# üéØ Job Classification Pipeline

Un pipeline complet de Machine Learning pour la classification automatique de postes/m√©tiers bas√© sur les comp√©tences, descriptions et certifications.

## üìã Table des mati√®res

- [Description](#-description)
- [Structure du projet](#-structure-du-projet)
- [Technologies utilis√©es](#-technologies-utilis√©es)
- [Installation](#-installation)
- [Utilisation](#-utilisation)
- [Pipeline de traitement](#-pipeline-de-traitement)
- [Mod√®les et performances](#-mod√®les-et-performances)
- [R√©sultats](#-r√©sultats)

## üéØ Description

Ce projet impl√©mente un syst√®me de classification multi-classes capable de pr√©dire le titre d'un poste √† partir de :
- **Comp√©tences techniques** (Skills)
- **Description du poste** (Job Description)
- **Certifications** (Certifications)

Le syst√®me utilise plusieurs algorithmes de Machine Learning optimis√©s avec GridSearchCV et suit les exp√©riences avec MLflow.

## üìÅ Structure du projet

```
job-classification/
‚îÇ
‚îú‚îÄ‚îÄ jobs.csv                              # Dataset d'origine
‚îÇ
‚îú‚îÄ‚îÄ 1_Preprocessing.ipynb                 # Nettoyage et pr√©paration des donn√©es
‚îú‚îÄ‚îÄ 2_Feature_Engineering.ipynb           # Cr√©ation des features
‚îú‚îÄ‚îÄ 3_Modeling_GridSearch.ipynb           # Entra√Ænement et optimisation des mod√®les
‚îú‚îÄ‚îÄ 4_MLflow.ipynb                        # Tracking et gestion des exp√©riences
‚îÇ
‚îú‚îÄ‚îÄ preprocessed_data.pkl                 # Donn√©es apr√®s preprocessing
‚îú‚îÄ‚îÄ feature_sets.pkl                      # Diff√©rentes repr√©sentations de features
‚îú‚îÄ‚îÄ modeling_results_gridsearch.pkl       # R√©sultats de tous les mod√®les
‚îú‚îÄ‚îÄ label_encoder.pkl                     # Encoder pour les labels
‚îÇ
‚îú‚îÄ‚îÄ mlflow.db                             # Base de donn√©es MLflow
‚îú‚îÄ‚îÄ mlruns/                               # R√©pertoire des exp√©riences MLflow
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt                      # D√©pendances Python
‚îî‚îÄ‚îÄ README.md                             # Documentation (ce fichier)
```

## üõ†Ô∏è Technologies utilis√©es

### Librairies principales
- **pandas** : Manipulation de donn√©es
- **numpy** : Calculs num√©riques
- **scikit-learn** : Algorithmes ML et outils
- **scipy** : Matrices creuses et op√©rations scientifiques
- **MLflow** : Tracking des exp√©riences et gestion des mod√®les

### Algorithmes de classification test√©s
1. **Logistic Regression** - Baseline lin√©aire
2. **Multinomial Naive Bayes** - Adapt√© au texte
3. **Linear SVC** - Support Vector Classifier
4. **Random Forest** - Ensemble de Decision Trees
5. **K-Nearest Neighbors (KNN)** - Classification par proximit√©
6. **Decision Tree** - Arbre de d√©cision simple

## üöÄ Installation

### Pr√©requis
- Python 3.8 ou sup√©rieur
- pip

### √âtapes d'installation

1. **Cloner le repository** (ou t√©l√©charger les fichiers)

2. **Cr√©er un environnement virtuel** (recommand√©)
```bash
python -m venv venv

# Windows
venv\Scripts\activate

# Linux/Mac
source venv/bin/activate
```

3. **Installer les d√©pendances**
```bash
pip install -r requirements.txt
```

## üíª Utilisation

### Ordre d'ex√©cution des notebooks

Ex√©cutez les notebooks dans l'ordre suivant :

#### 1Ô∏è‚É£ Preprocessing (1_Preprocessing.ipynb)
```bash
jupyter notebook 1_Preprocessing.ipynb
```
**Objectif** : Nettoyer les donn√©es, g√©rer les valeurs manquantes, encoder les labels
**Sortie** : `preprocessed_data.pkl`, `label_encoder.pkl`

#### 2Ô∏è‚É£ Feature Engineering (2_Feature_Engineering.ipynb)
```bash
jupyter notebook 2_Feature_Engineering.ipynb
```
**Objectif** : Cr√©er diff√©rentes repr√©sentations des features textuelles
**Sortie** : `feature_sets.pkl` avec 5 types de features :
- **TF-IDF** (5000 features)
- **Count Vectorizer** (3000 features)
- **TF-IDF + SVD** (300 composantes)
- **Features statistiques** (5 features)
- **TF-IDF + Stats combin√©es** (5005 features)

#### 3Ô∏è‚É£ Modeling avec GridSearchCV (3_Modeling_GridSearch.ipynb)
```bash
jupyter notebook 3_Modeling_GridSearch.ipynb
```
**Objectif** : Entra√Æner et optimiser plusieurs mod√®les
**Sortie** : `modeling_results_gridsearch.pkl`

**Mod√®les test√©s** :
- 6 algorithmes diff√©rents
- 4 configurations de features
- ~20 combinaisons au total
- Optimisation des hyperparam√®tres avec GridSearchCV

#### 4Ô∏è‚É£ MLflow Tracking (4_MLflow.ipynb)
```bash
jupyter notebook 4_MLflow.ipynb
```
**Objectif** : Enregistrer tous les mod√®les et m√©triques dans MLflow
**Sortie** : Exp√©riences MLflow accessibles via l'interface web

### Visualiser les exp√©riences MLflow

Apr√®s avoir ex√©cut√© le notebook MLflow :

```bash
mlflow ui
```

Puis ouvrez votre navigateur √† : `http://localhost:5000`

## üîÑ Pipeline de traitement

### 1. Preprocessing
- Chargement du dataset (`jobs.csv`)
- Nettoyage du texte (minuscules, ponctuation, caract√®res sp√©ciaux)
- Combinaison des features textuelles
- Encodage des labels (Job Title)
- Split train/test (80/20)

### 2. Feature Engineering
- **TF-IDF Vectorization** : Transformation en vecteurs TF-IDF
- **Count Vectorization** : Comptage de fr√©quences des mots
- **Dimensionality Reduction** : R√©duction avec TruncatedSVD
- **Statistical Features** : Features statistiques (longueur, nombre de mots, etc.)
- **Combined Features** : Combinaison TF-IDF + Stats

### 3. Modeling
- Entra√Ænement de 6 mod√®les diff√©rents
- GridSearchCV pour optimisation des hyperparam√®tres
- Cross-validation 3-fold
- √âvaluation sur l'ensemble de test
- S√©lection automatique du meilleur mod√®le

### 4. Tracking
- Enregistrement de tous les mod√®les dans MLflow
- Logging des m√©triques (accuracy, precision, recall, F1)
- Sauvegarde des hyperparam√®tres optimaux
- Enregistrement du meilleur mod√®le pour d√©ploiement

## üìä Mod√®les et performances

### M√©triques √©valu√©es
- **Accuracy** : Pr√©cision globale
- **Precision** (weighted & macro)
- **Recall** (weighted & macro)
- **F1-Score** (weighted & macro)
- **Training Time** : Temps d'entra√Ænement
- **Prediction Time** : Temps de pr√©diction

### Configuration optimale (exemple)
Bas√© sur les r√©sultats des notebooks :
- **Meilleur mod√®le** : Random Forest avec features combin√©es
- **F1-Score** : ~0.75+ (variable selon les donn√©es)
- **Nombre de classes** : 119 job titles diff√©rents

### Grilles d'hyperparam√®tres

**Logistic Regression** :
- C: [0.1, 1, 10, 100]
- solver: ['saga', 'liblinear']
- max_iter: [1000, 2000]

**Random Forest** :
- n_estimators: [50, 100, 200]
- max_depth: [10, 20, 30]
- min_samples_split: [2, 5]

**KNN** :
- n_neighbors: [3, 5, 7, 9]
- weights: ['uniform', 'distance']

*(Voir notebook 3 pour la liste compl√®te)*

## üìà R√©sultats

Les r√©sultats d√©taill√©s sont disponibles dans :
1. **Le notebook 3** : Tableaux de comparaison des mod√®les
2. **MLflow UI** : Visualisation interactive des exp√©riences
3. **`modeling_results_gridsearch.pkl`** : R√©sultats sauvegard√©s

### Exemple de r√©sultats typiques :

| Mod√®le | Features | F1-Score | Accuracy | Training Time |
|--------|----------|----------|----------|---------------|
| Random Forest | Combined | 0.75+ | 0.75+ | ~40s |
| Logistic Regression | TF-IDF | 0.73+ | 0.73+ | ~130s |
| Linear SVC | TF-IDF | 0.71+ | 0.72+ | ~6s |

*(R√©sultats indicatifs bas√©s sur les notebooks fournis)*

## üîç Analyse des donn√©es

### Dataset
- **Nombre total d'exemples** : 2,458 jobs
- **Nombre de classes** : 119 job titles diff√©rents
- **Split** : 80% train (1,966) / 20% test (492)
- **Features** : Skills, Job Description, Certifications

### Distribution
- La classe la plus fr√©quente : "Backend Developer" (45 occurrences)
- Dataset relativement √©quilibr√© entre les classes principales

## üîß Maintenance et am√©lioration

### Prochaines √©tapes possibles
1. **Deep Learning** : Tester des mod√®les BERT ou transformers
2. **Feature Engineering** : Ajouter des embeddings (Word2Vec, GloVe)
3. **Ensemble Methods** : Stacking ou voting de plusieurs mod√®les
4. **D√©s√©quilibre de classes** : SMOTE ou class weights
5. **D√©ploiement** : API REST avec Flask/FastAPI
6. **Interface utilisateur** : Application web pour les pr√©dictions

### R√©entra√Ænement
Pour r√©entra√Æner avec de nouvelles donn√©es :
1. Remplacer `jobs.csv` avec les nouvelles donn√©es
2. Ex√©cuter les notebooks 1-4 dans l'ordre
3. Les mod√®les seront automatiquement sauvegard√©s

## üìù Notes importantes

- Le preprocessing nettoie et normalise le texte en fran√ßais
- GridSearchCV utilise 3-fold cross-validation
- Les mod√®les sont sauvegard√©s au format pickle
- MLflow utilise une base SQLite locale (`mlflow.db`)
- Les features combin√©es ne fonctionnent pas avec tous les mod√®les (certains n√©cessitent une normalisation)

## ü§ù Contribution

Pour contribuer :
1. Fork le projet
2. Cr√©er une branche (`git checkout -b feature/amelioration`)
3. Commit les changements (`git commit -m 'Ajout d'une fonctionnalit√©'`)
4. Push vers la branche (`git push origin feature/amelioration`)
5. Ouvrir une Pull Request

## üìÑ Licence

Ce projet est sous licence MIT - voir le fichier LICENSE pour plus de d√©tails.

## üë§ Auteur

D√©velopp√© dans le cadre d'un projet de Machine Learning pour la classification automatique de postes.

## üôè Remerciements

- scikit-learn pour les algorithmes de ML
- MLflow pour le tracking des exp√©riences
- Pandas pour la manipulation de donn√©es
- La communaut√© open-source

---

**Note** : Ce README d√©crit un projet complet de classification multi-classes avec optimisation d'hyperparam√®tres et tracking MLflow. Pour toute question ou suggestion, n'h√©sitez pas √† ouvrir une issue.
