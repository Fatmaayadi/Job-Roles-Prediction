{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. MLflow\n",
    "\n",
    "Ce notebook enregistre tous les modèles, métriques et le meilleur modèle avec MLflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import des bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bibliothèques importées avec succès\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Bibliothèques importées avec succès\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration de MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/16 13:28:04 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.schemas\n",
      "2026/02/16 13:28:04 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.tables\n",
      "2026/02/16 13:28:04 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.types\n",
      "2026/02/16 13:28:04 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.constraints\n",
      "2026/02/16 13:28:04 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.defaults\n",
      "2026/02/16 13:28:04 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.comments\n",
      "2026/02/16 13:28:05 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2026/02/16 13:28:05 INFO mlflow.store.db.utils: Updating database tables\n",
      "2026/02/16 13:28:05 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
      "2026/02/16 13:28:05 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n",
      "2026/02/16 13:28:05 INFO alembic.runtime.migration: Running upgrade  -> 451aebb31d03, add metric step\n",
      "2026/02/16 13:28:06 INFO alembic.runtime.migration: Running upgrade 451aebb31d03 -> 90e64c465722, migrate user column to tags\n",
      "2026/02/16 13:28:06 INFO alembic.runtime.migration: Running upgrade 90e64c465722 -> 181f10493468, allow nulls for metric values\n",
      "2026/02/16 13:28:06 INFO alembic.runtime.migration: Running upgrade 181f10493468 -> df50e92ffc5e, Add Experiment Tags Table\n",
      "2026/02/16 13:28:06 INFO alembic.runtime.migration: Running upgrade df50e92ffc5e -> 7ac759974ad8, Update run tags with larger limit\n",
      "2026/02/16 13:28:06 INFO alembic.runtime.migration: Running upgrade 7ac759974ad8 -> 89d4b8295536, create latest metrics table\n",
      "2026/02/16 13:28:06 INFO alembic.runtime.migration: Running upgrade 89d4b8295536 -> 2b4d017a5e9b, add model registry tables to db\n",
      "2026/02/16 13:28:06 INFO alembic.runtime.migration: Running upgrade 2b4d017a5e9b -> cfd24bdc0731, Update run status constraint with killed\n",
      "2026/02/16 13:28:06 INFO alembic.runtime.migration: Running upgrade cfd24bdc0731 -> 0a8213491aaa, drop_duplicate_killed_constraint\n",
      "2026/02/16 13:28:06 INFO alembic.runtime.migration: Running upgrade 0a8213491aaa -> 728d730b5ebd, add registered model tags table\n",
      "2026/02/16 13:28:06 INFO alembic.runtime.migration: Running upgrade 728d730b5ebd -> 27a6a02d2cf1, add model version tags table\n",
      "2026/02/16 13:28:06 INFO alembic.runtime.migration: Running upgrade 27a6a02d2cf1 -> 84291f40a231, add run_link to model_version\n",
      "2026/02/16 13:28:06 INFO alembic.runtime.migration: Running upgrade 84291f40a231 -> a8c4a736bde6, allow nulls for run_id\n",
      "2026/02/16 13:28:06 INFO alembic.runtime.migration: Running upgrade a8c4a736bde6 -> 39d1c3be5f05, add_is_nan_constraint_for_metrics_tables_if_necessary\n",
      "2026/02/16 13:28:07 INFO alembic.runtime.migration: Running upgrade 39d1c3be5f05 -> c48cb773bb87, reset_default_value_for_is_nan_in_metrics_table_for_mysql\n",
      "2026/02/16 13:28:07 INFO alembic.runtime.migration: Running upgrade c48cb773bb87 -> bd07f7e963c5, create index on run_uuid\n",
      "2026/02/16 13:28:07 INFO alembic.runtime.migration: Running upgrade bd07f7e963c5 -> 0c779009ac13, add deleted_time field to runs table\n",
      "2026/02/16 13:28:07 INFO alembic.runtime.migration: Running upgrade 0c779009ac13 -> cc1f77228345, change param value length to 500\n",
      "2026/02/16 13:28:07 INFO alembic.runtime.migration: Running upgrade cc1f77228345 -> 97727af70f4d, Add creation_time and last_update_time to experiments table\n",
      "2026/02/16 13:28:07 INFO alembic.runtime.migration: Running upgrade 97727af70f4d -> 3500859a5d39, Add Model Aliases table\n",
      "2026/02/16 13:28:07 INFO alembic.runtime.migration: Running upgrade 3500859a5d39 -> 7f2a7d5fae7d, add datasets inputs input_tags tables\n",
      "2026/02/16 13:28:07 INFO alembic.runtime.migration: Running upgrade 7f2a7d5fae7d -> 2d6e25af4d3e, increase max param val length from 500 to 8000\n",
      "2026/02/16 13:28:07 INFO alembic.runtime.migration: Running upgrade 2d6e25af4d3e -> acf3f17fdcc7, add storage location field to model versions\n",
      "2026/02/16 13:28:07 INFO alembic.runtime.migration: Running upgrade acf3f17fdcc7 -> 867495a8f9d4, add trace tables\n",
      "2026/02/16 13:28:07 INFO alembic.runtime.migration: Running upgrade 867495a8f9d4 -> 5b0e9adcef9c, add cascade deletion to trace tables foreign keys\n",
      "2026/02/16 13:28:07 INFO alembic.runtime.migration: Running upgrade 5b0e9adcef9c -> 4465047574b1, increase max dataset schema size\n",
      "2026/02/16 13:28:07 INFO alembic.runtime.migration: Running upgrade 4465047574b1 -> f5a4f2784254, increase run tag value limit to 8000\n",
      "2026/02/16 13:28:08 INFO alembic.runtime.migration: Running upgrade f5a4f2784254 -> 0584bdc529eb, add cascading deletion to datasets from experiments\n",
      "2026/02/16 13:28:08 INFO alembic.runtime.migration: Running upgrade 0584bdc529eb -> 400f98739977, add logged model tables\n",
      "2026/02/16 13:28:08 INFO alembic.runtime.migration: Running upgrade 400f98739977 -> 6953534de441, add step to inputs table\n",
      "2026/02/16 13:28:08 INFO alembic.runtime.migration: Running upgrade 6953534de441 -> bda7b8c39065, increase_model_version_tag_value_limit\n",
      "2026/02/16 13:28:08 INFO alembic.runtime.migration: Running upgrade bda7b8c39065 -> cbc13b556ace, add V3 trace schema columns\n",
      "2026/02/16 13:28:08 INFO alembic.runtime.migration: Running upgrade cbc13b556ace -> 770bee3ae1dd, add assessments table\n",
      "2026/02/16 13:28:08 INFO alembic.runtime.migration: Running upgrade 770bee3ae1dd -> a1b2c3d4e5f6, add spans table\n",
      "2026/02/16 13:28:08 INFO alembic.runtime.migration: Running upgrade a1b2c3d4e5f6 -> de4033877273, create entity_associations table\n",
      "2026/02/16 13:28:08 INFO alembic.runtime.migration: Running upgrade de4033877273 -> 1a0cddfcaa16, Add webhooks and webhook_events tables\n",
      "2026/02/16 13:28:08 INFO alembic.runtime.migration: Running upgrade 1a0cddfcaa16 -> 534353b11cbc, add scorer tables\n",
      "2026/02/16 13:28:09 INFO alembic.runtime.migration: Running upgrade 534353b11cbc -> 71994744cf8e, add evaluation datasets\n",
      "2026/02/16 13:28:09 INFO alembic.runtime.migration: Running upgrade 71994744cf8e -> 3da73c924c2f, add outputs to dataset record\n",
      "2026/02/16 13:28:09 INFO alembic.runtime.migration: Running upgrade 3da73c924c2f -> bf29a5ff90ea, add jobs table\n",
      "2026/02/16 13:28:09 INFO alembic.runtime.migration: Running upgrade bf29a5ff90ea -> 1bd49d398cd23, add secrets tables\n",
      "2026/02/16 13:28:09 INFO alembic.runtime.migration: Running upgrade 1bd49d398cd23 -> b7c8d9e0f1a2, add trace metrics table\n",
      "2026/02/16 13:28:09 INFO alembic.runtime.migration: Running upgrade b7c8d9e0f1a2 -> 5d2d30f0abce, update job table\n",
      "2026/02/16 13:28:09 INFO alembic.runtime.migration: Running upgrade 5d2d30f0abce -> c9d4e5f6a7b8, add routing strategy to endpoints and linkage type to mappings\n",
      "2026/02/16 13:28:09 INFO alembic.runtime.migration: Running upgrade c9d4e5f6a7b8 -> 2c33131f4dae, add online_scoring_configs table\n",
      "2026/02/16 13:28:09 INFO alembic.runtime.migration: Running upgrade 2c33131f4dae -> d3e4f5a6b7c8, add display_name to endpoint_bindings\n",
      "2026/02/16 13:28:10 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
      "2026/02/16 13:28:10 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n",
      "2026/02/16 13:28:10 INFO mlflow.tracking.fluent: Experiment with name 'Job_Classification_Pipeline' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expérience MLflow configurée: Job_Classification_Pipeline\n",
      "Experiment ID: 1\n",
      "Tracking URI: sqlite:///mlflow.db\n"
     ]
    }
   ],
   "source": [
    "# Définir le nom de l'expérience\n",
    "experiment_name = \"Job_Classification_Pipeline\"\n",
    "\n",
    "# Créer ou récupérer l'expérience\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# Obtenir l'ID de l'expérience\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "experiment_id = experiment.experiment_id\n",
    "\n",
    "print(f\"Expérience MLflow configurée: {experiment_name}\")\n",
    "print(f\"Experiment ID: {experiment_id}\")\n",
    "print(f\"Tracking URI: {mlflow.get_tracking_uri()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des résultats du modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Résultats chargés avec succès\n",
      "Nombre de modèles entraînés: 20\n",
      "Meilleur modèle: Random_Forest_Combined\n"
     ]
    }
   ],
   "source": [
    "# Charger les résultats du modeling\n",
    "with open('../data/pkl/modeling_results_gridsearch.pkl', 'rb') as f:\n",
    "    modeling_results = pickle.load(f)\n",
    "\n",
    "all_results = modeling_results['all_results']\n",
    "trained_models = modeling_results['trained_models']\n",
    "best_model_key = modeling_results['best_model_key']\n",
    "best_model = modeling_results['best_model']\n",
    "best_metrics = modeling_results['best_metrics']\n",
    "label_encoder = modeling_results['label_encoder']\n",
    "\n",
    "print(f\"Résultats chargés avec succès\")\n",
    "print(f\"Nombre de modèles entraînés: {len(trained_models)}\")\n",
    "print(f\"Meilleur modèle: {best_model_key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enregistrement de tous les modèles dans MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ENREGISTREMENT DE TOUS LES MODÈLES DANS MLFLOW\n",
      "================================================================================\n",
      "\n",
      "[1/20] Enregistrement: Logistic_Regression_TF-IDF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/16 13:28:17 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✓ Run ID: 8a914ae59ee444ce8fc52cba9dbbeac1\n",
      "   ✓ F1-Score: 0.7329\n",
      "   ✓ Meilleur modèle: no\n",
      "\n",
      "[2/20] Enregistrement: Multinomial_NB_TF-IDF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/16 13:28:48 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✓ Run ID: 7957eed4cb2a46c4bc390bb357e86c08\n",
      "   ✓ F1-Score: 0.6363\n",
      "   ✓ Meilleur modèle: no\n",
      "\n",
      "[3/20] Enregistrement: Linear_SVC_TF-IDF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/16 13:29:08 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✓ Run ID: 6bbdecc04b184c9dbe1cd3411886ce1f\n",
      "   ✓ F1-Score: 0.7163\n",
      "   ✓ Meilleur modèle: no\n",
      "\n",
      "[4/20] Enregistrement: Random_Forest_TF-IDF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/16 13:29:26 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✓ Run ID: 6ef08df9b6c7419fb948f7b7903b0561\n",
      "   ✓ F1-Score: 0.7397\n",
      "   ✓ Meilleur modèle: no\n",
      "\n",
      "[5/20] Enregistrement: KNN_TF-IDF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/16 13:29:46 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✓ Run ID: 675a79ec5091449e92567ccae89269cc\n",
      "   ✓ F1-Score: 0.6238\n",
      "   ✓ Meilleur modèle: no\n",
      "\n",
      "[6/20] Enregistrement: Decision_Tree_TF-IDF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/16 13:30:03 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✓ Run ID: 8862523d29414aaab964423bb6df6300\n",
      "   ✓ F1-Score: 0.6820\n",
      "   ✓ Meilleur modèle: no\n",
      "\n",
      "[7/20] Enregistrement: Logistic_Regression_Count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/16 13:30:20 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✓ Run ID: a648556b46d04685bf9c64d617e15176\n",
      "   ✓ F1-Score: 0.7405\n",
      "   ✓ Meilleur modèle: no\n",
      "\n",
      "[8/20] Enregistrement: Multinomial_NB_Count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/16 13:30:37 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✓ Run ID: ead8a3fd079b4e80817e33b16fee35cf\n",
      "   ✓ F1-Score: 0.6433\n",
      "   ✓ Meilleur modèle: no\n",
      "\n",
      "[9/20] Enregistrement: Linear_SVC_Count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/16 13:30:54 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✓ Run ID: d9135b191253466ea94b0be93f6a49c5\n",
      "   ✓ F1-Score: 0.7221\n",
      "   ✓ Meilleur modèle: no\n",
      "\n",
      "[10/20] Enregistrement: Random_Forest_Count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/16 13:31:15 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✓ Run ID: c7d9b0443b994a37a2486b3cd1ef99cd\n",
      "   ✓ F1-Score: 0.7510\n",
      "   ✓ Meilleur modèle: no\n",
      "\n",
      "[11/20] Enregistrement: KNN_Count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/16 13:31:39 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✓ Run ID: 4aeb58f7d09c4cdea07bb74124fee7fc\n",
      "   ✓ F1-Score: 0.5377\n",
      "   ✓ Meilleur modèle: no\n",
      "\n",
      "[12/20] Enregistrement: Decision_Tree_Count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/16 13:32:01 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✓ Run ID: 886dd4d626454f2a97c60ed78931238c\n",
      "   ✓ F1-Score: 0.6720\n",
      "   ✓ Meilleur modèle: no\n",
      "\n",
      "[13/20] Enregistrement: Logistic_Regression_SVD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/16 13:32:21 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✓ Run ID: 6e8891a9c6d44f33bfe5a733d70c5637\n",
      "   ✓ F1-Score: 0.7333\n",
      "   ✓ Meilleur modèle: no\n",
      "\n",
      "[14/20] Enregistrement: Linear_SVC_SVD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/16 13:32:41 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✓ Run ID: ef6dc590fd1a40ef89814945076522ef\n",
      "   ✓ F1-Score: 0.7204\n",
      "   ✓ Meilleur modèle: no\n",
      "\n",
      "[15/20] Enregistrement: Random_Forest_SVD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/16 13:33:00 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✓ Run ID: b9da542b8f1c490f9845f5d6dafbaeba\n",
      "   ✓ F1-Score: 0.6863\n",
      "   ✓ Meilleur modèle: no\n",
      "\n",
      "[16/20] Enregistrement: KNN_SVD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/16 13:33:17 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✓ Run ID: 0d3e1ad8a13c413480bd9b1fbb4fa18e\n",
      "   ✓ F1-Score: 0.6316\n",
      "   ✓ Meilleur modèle: no\n",
      "\n",
      "[17/20] Enregistrement: Decision_Tree_SVD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/16 13:33:35 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✓ Run ID: e6eb2921b86242108146eaabf530eb50\n",
      "   ✓ F1-Score: 0.4579\n",
      "   ✓ Meilleur modèle: no\n",
      "\n",
      "[18/20] Enregistrement: Multinomial_NB_Combined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/16 13:33:51 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✓ Run ID: 13d29faf3ceb4e9abc58b7485b544d32\n",
      "   ✓ F1-Score: 0.6329\n",
      "   ✓ Meilleur modèle: no\n",
      "\n",
      "[19/20] Enregistrement: Random_Forest_Combined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/16 13:34:08 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✓ Run ID: 040f19c8b1154159a2f5029ce8f464d1\n",
      "   ✓ F1-Score: 0.7556\n",
      "   ✓ Meilleur modèle: yes\n",
      "\n",
      "[20/20] Enregistrement: Decision_Tree_Combined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/16 13:34:26 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✓ Run ID: 03973d30fc5b45cfafad88e69c795b5a\n",
      "   ✓ F1-Score: 0.6822\n",
      "   ✓ Meilleur modèle: no\n",
      "\n",
      "================================================================================\n",
      "TOUS LES MODÈLES ENREGISTRÉS DANS MLFLOW\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"ENREGISTREMENT DE TOUS LES MODÈLES DANS MLFLOW\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "run_ids = {}\n",
    "total_models = len(trained_models)\n",
    "current_model = 0\n",
    "\n",
    "for model_key, model_info in trained_models.items():\n",
    "    current_model += 1\n",
    "    print(f\"\\n[{current_model}/{total_models}] Enregistrement: {model_key}\")\n",
    "    \n",
    "    # Extraire le nom du modèle et la configuration des features\n",
    "    model_name, feature_config = model_key.rsplit('_', 1)\n",
    "    \n",
    "    # Démarrer un run MLflow\n",
    "    with mlflow.start_run(run_name=model_key) as run:\n",
    "        # Enregistrer les paramètres\n",
    "        mlflow.log_param(\"model_type\", model_name)\n",
    "        mlflow.log_param(\"feature_config\", feature_config)\n",
    "        mlflow.log_param(\"num_classes\", len(label_encoder.classes_))\n",
    "        \n",
    "        # Enregistrer les hyperparamètres du modèle\n",
    "        model_params = model_info['model'].get_params()\n",
    "        for param_name, param_value in model_params.items():\n",
    "            # Convertir les valeurs non-sérialisables\n",
    "            if param_value is None or isinstance(param_value, (int, float, str, bool)):\n",
    "                mlflow.log_param(f\"model_{param_name}\", param_value)\n",
    "        \n",
    "        # Enregistrer toutes les métriques\n",
    "        metrics = model_info['metrics']\n",
    "        mlflow.log_metric(\"accuracy\", metrics['accuracy'])\n",
    "        mlflow.log_metric(\"precision_weighted\", metrics['precision_weighted'])\n",
    "        mlflow.log_metric(\"recall_weighted\", metrics['recall_weighted'])\n",
    "        mlflow.log_metric(\"f1_weighted\", metrics['f1_weighted'])\n",
    "        mlflow.log_metric(\"precision_macro\", metrics['precision_macro'])\n",
    "        mlflow.log_metric(\"recall_macro\", metrics['recall_macro'])\n",
    "        mlflow.log_metric(\"f1_macro\", metrics['f1_macro'])\n",
    "        mlflow.log_metric(\"training_time\", metrics['training_time'])\n",
    "        mlflow.log_metric(\"prediction_time\", metrics['prediction_time'])\n",
    "        \n",
    "        # Enregistrer le modèle\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=model_info['model'],\n",
    "            artifact_path=\"model\",\n",
    "            registered_model_name=None  # Ne pas enregistrer dans le Model Registry pour l'instant\n",
    "        )\n",
    "        \n",
    "        # Ajouter un tag pour identifier si c'est le meilleur modèle\n",
    "        is_best = \"yes\" if model_key == best_model_key else \"no\"\n",
    "        mlflow.set_tag(\"best_model\", is_best)\n",
    "        mlflow.set_tag(\"timestamp\", datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "        \n",
    "        # Stocker le run_id\n",
    "        run_ids[model_key] = run.info.run_id\n",
    "        \n",
    "        print(f\"   ✓ Run ID: {run.info.run_id}\")\n",
    "        print(f\"   ✓ F1-Score: {metrics['f1_weighted']:.4f}\")\n",
    "        print(f\"   ✓ Meilleur modèle: {is_best}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"TOUS LES MODÈLES ENREGISTRÉS DANS MLFLOW\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enregistrement spécial du meilleur modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ENREGISTREMENT DU MEILLEUR MODÈLE DANS LE MODEL REGISTRY\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/16 13:34:44 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "Successfully registered model 'Job_Classification_Best_Model'.\n",
      "Created version '1' of model 'Job_Classification_Best_Model'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Meilleur modèle enregistré dans le Model Registry\n",
      "✓ Run ID: 19644568d43f426693a36147e1693345\n",
      "✓ Model Name: Job_Classification_Best_Model\n",
      "✓ Model: Random_Forest\n",
      "✓ Features: Combined\n",
      "✓ F1-Score: 0.7556\n",
      "✓ Accuracy: 0.7663\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ENREGISTREMENT DU MEILLEUR MODÈLE DANS LE MODEL REGISTRY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Créer un run dédié pour le meilleur modèle\n",
    "with mlflow.start_run(run_name=f\"BEST_MODEL_{best_model_key}\") as run:\n",
    "    # Extraire les informations\n",
    "    model_name, feature_config = best_model_key.rsplit('_', 1)\n",
    "    \n",
    "    # Enregistrer les paramètres\n",
    "    mlflow.log_param(\"model_type\", model_name)\n",
    "    mlflow.log_param(\"feature_config\", feature_config)\n",
    "    mlflow.log_param(\"num_classes\", len(label_encoder.classes_))\n",
    "    mlflow.log_param(\"selection_criteria\", \"f1_weighted\")\n",
    "    \n",
    "    # Enregistrer les hyperparamètres\n",
    "    model_params = best_model.get_params()\n",
    "    for param_name, param_value in model_params.items():\n",
    "        if param_value is None or isinstance(param_value, (int, float, str, bool)):\n",
    "            mlflow.log_param(f\"model_{param_name}\", param_value)\n",
    "    \n",
    "    # Enregistrer toutes les métriques\n",
    "    mlflow.log_metric(\"accuracy\", best_metrics['accuracy'])\n",
    "    mlflow.log_metric(\"precision_weighted\", best_metrics['precision_weighted'])\n",
    "    mlflow.log_metric(\"recall_weighted\", best_metrics['recall_weighted'])\n",
    "    mlflow.log_metric(\"f1_weighted\", best_metrics['f1_weighted'])\n",
    "    mlflow.log_metric(\"precision_macro\", best_metrics['precision_macro'])\n",
    "    mlflow.log_metric(\"recall_macro\", best_metrics['recall_macro'])\n",
    "    mlflow.log_metric(\"f1_macro\", best_metrics['f1_macro'])\n",
    "    mlflow.log_metric(\"training_time\", best_metrics['training_time'])\n",
    "    mlflow.log_metric(\"prediction_time\", best_metrics['prediction_time'])\n",
    "    \n",
    "    # Enregistrer le modèle dans le Model Registry\n",
    "    model_uri = mlflow.sklearn.log_model(\n",
    "        sk_model=best_model,\n",
    "        artifact_path=\"best_model\",\n",
    "        registered_model_name=\"Job_Classification_Best_Model\"\n",
    "    )\n",
    "    \n",
    "    # Ajouter des tags\n",
    "    mlflow.set_tag(\"best_model\", \"yes\")\n",
    "    mlflow.set_tag(\"model_version\", \"production_candidate\")\n",
    "    mlflow.set_tag(\"timestamp\", datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    mlflow.set_tag(\"pipeline_stage\", \"complete\")\n",
    "    \n",
    "    best_run_id = run.info.run_id\n",
    "    \n",
    "    print(f\"\\n✓ Meilleur modèle enregistré dans le Model Registry\")\n",
    "    print(f\"✓ Run ID: {best_run_id}\")\n",
    "    print(f\"✓ Model Name: Job_Classification_Best_Model\")\n",
    "    print(f\"✓ Model: {model_name}\")\n",
    "    print(f\"✓ Features: {feature_config}\")\n",
    "    print(f\"✓ F1-Score: {best_metrics['f1_weighted']:.4f}\")\n",
    "    print(f\"✓ Accuracy: {best_metrics['accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enregistrement du tableau comparatif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Métadonnées de l'expérience enregistrées\n",
      "✓ Tableau comparatif enregistré comme artifact\n"
     ]
    }
   ],
   "source": [
    "# Créer un run pour les métadonnées de l'expérience\n",
    "with mlflow.start_run(run_name=\"Experiment_Metadata\") as run:\n",
    "    # Enregistrer le tableau de comparaison comme artifact\n",
    "    all_results.to_csv('../data/csv/mlflow_comparison.csv', index=False)\n",
    "    mlflow.log_artifact('../data/csv/mlflow_comparison.csv', artifact_path=\"comparison\")\n",
    "    \n",
    "    # Enregistrer des statistiques globales\n",
    "    mlflow.log_metric(\"total_models_trained\", len(trained_models))\n",
    "    mlflow.log_metric(\"best_f1_score\", best_metrics['f1_weighted'])\n",
    "    mlflow.log_metric(\"best_accuracy\", best_metrics['accuracy'])\n",
    "    mlflow.log_metric(\"avg_f1_score\", all_results['f1_weighted'].mean())\n",
    "    mlflow.log_metric(\"std_f1_score\", all_results['f1_weighted'].std())\n",
    "    \n",
    "    # Tags pour l'expérience\n",
    "    mlflow.set_tag(\"experiment_type\", \"model_comparison\")\n",
    "    mlflow.set_tag(\"timestamp\", datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    mlflow.set_tag(\"pipeline_complete\", \"yes\")\n",
    "    \n",
    "    print(\"\\n✓ Métadonnées de l'expérience enregistrées\")\n",
    "    print(f\"✓ Tableau comparatif enregistré comme artifact\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation des runs MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TOP 10 RUNS PAR F1-SCORE\n",
      "================================================================================\n",
      "1. BEST_MODEL_Random_Forest_Combined ⭐ MEILLEUR\n",
      "   F1-Score: 0.7556 | Accuracy: 0.7663\n",
      "   Run ID: 19644568d43f426693a36147e1693345\n",
      "\n",
      "2. Random_Forest_Combined ⭐ MEILLEUR\n",
      "   F1-Score: 0.7556 | Accuracy: 0.7663\n",
      "   Run ID: 040f19c8b1154159a2f5029ce8f464d1\n",
      "\n",
      "3. Random_Forest_Count\n",
      "   F1-Score: 0.7510 | Accuracy: 0.7622\n",
      "   Run ID: c7d9b0443b994a37a2486b3cd1ef99cd\n",
      "\n",
      "4. Logistic_Regression_Count\n",
      "   F1-Score: 0.7405 | Accuracy: 0.7419\n",
      "   Run ID: a648556b46d04685bf9c64d617e15176\n",
      "\n",
      "5. Random_Forest_TF-IDF\n",
      "   F1-Score: 0.7397 | Accuracy: 0.7520\n",
      "   Run ID: 6ef08df9b6c7419fb948f7b7903b0561\n",
      "\n",
      "6. Logistic_Regression_SVD\n",
      "   F1-Score: 0.7333 | Accuracy: 0.7337\n",
      "   Run ID: 6e8891a9c6d44f33bfe5a733d70c5637\n",
      "\n",
      "7. Logistic_Regression_TF-IDF\n",
      "   F1-Score: 0.7329 | Accuracy: 0.7337\n",
      "   Run ID: 8a914ae59ee444ce8fc52cba9dbbeac1\n",
      "\n",
      "8. Linear_SVC_Count\n",
      "   F1-Score: 0.7221 | Accuracy: 0.7256\n",
      "   Run ID: d9135b191253466ea94b0be93f6a49c5\n",
      "\n",
      "9. Linear_SVC_SVD\n",
      "   F1-Score: 0.7204 | Accuracy: 0.7276\n",
      "   Run ID: ef6dc590fd1a40ef89814945076522ef\n",
      "\n",
      "10. Linear_SVC_TF-IDF\n",
      "   F1-Score: 0.7163 | Accuracy: 0.7215\n",
      "   Run ID: 6bbdecc04b184c9dbe1cd3411886ce1f\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Récupérer tous les runs de l'expérience\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "runs = client.search_runs(\n",
    "    experiment_ids=[experiment_id],\n",
    "    order_by=[\"metrics.f1_weighted DESC\"]\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TOP 10 RUNS PAR F1-SCORE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for i, run in enumerate(runs[:10], 1):\n",
    "    run_name = run.data.tags.get('mlflow.runName', 'N/A')\n",
    "    f1_score = run.data.metrics.get('f1_weighted', 0)\n",
    "    accuracy = run.data.metrics.get('accuracy', 0)\n",
    "    is_best = run.data.tags.get('best_model', 'no')\n",
    "    \n",
    "    best_marker = \" ⭐ MEILLEUR\" if is_best == \"yes\" else \"\"\n",
    "    \n",
    "    print(f\"{i}. {run_name}{best_marker}\")\n",
    "    print(f\"   F1-Score: {f1_score:.4f} | Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"   Run ID: {run.info.run_id}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistiques de l'expérience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STATISTIQUES DE L'EXPÉRIENCE\n",
      "================================================================================\n",
      "\n",
      "Nombre total de runs: 22\n",
      "\n",
      "F1-Score (weighted):\n",
      "  Maximum: 0.7556\n",
      "  Minimum: 0.0000\n",
      "  Moyenne: 0.6479\n",
      "  Écart-type: 0.1587\n",
      "\n",
      "Accuracy:\n",
      "  Maximum: 0.7663\n",
      "  Minimum: 0.0000\n",
      "  Moyenne: 0.6535\n",
      "  Écart-type: 0.1606\n"
     ]
    }
   ],
   "source": [
    "# Calculer des statistiques\n",
    "f1_scores = [run.data.metrics.get('f1_weighted', 0) for run in runs]\n",
    "accuracies = [run.data.metrics.get('accuracy', 0) for run in runs]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STATISTIQUES DE L'EXPÉRIENCE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nNombre total de runs: {len(runs)}\")\n",
    "print(f\"\\nF1-Score (weighted):\")\n",
    "print(f\"  Maximum: {max(f1_scores):.4f}\")\n",
    "print(f\"  Minimum: {min(f1_scores):.4f}\")\n",
    "print(f\"  Moyenne: {np.mean(f1_scores):.4f}\")\n",
    "print(f\"  Écart-type: {np.std(f1_scores):.4f}\")\n",
    "\n",
    "print(f\"\\nAccuracy:\")\n",
    "print(f\"  Maximum: {max(accuracies):.4f}\")\n",
    "print(f\"  Minimum: {min(accuracies):.4f}\")\n",
    "print(f\"  Moyenne: {np.mean(accuracies):.4f}\")\n",
    "print(f\"  Écart-type: {np.std(accuracies):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Informations sur le Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "INFORMATIONS DU MODEL REGISTRY\n",
      "================================================================================\n",
      "\n",
      "Nom du modèle: Job_Classification_Best_Model\n",
      "Description: N/A\n",
      "\n",
      "Versions disponibles: 1\n",
      "\n",
      "  Version 1:\n",
      "    Stage: None\n",
      "    Run ID: 19644568d43f426693a36147e1693345\n",
      "    Status: READY\n"
     ]
    }
   ],
   "source": [
    "# Récupérer les informations du modèle enregistré\n",
    "registered_model_name = \"Job_Classification_Best_Model\"\n",
    "\n",
    "try:\n",
    "    registered_model = client.get_registered_model(registered_model_name)\n",
    "    latest_versions = client.get_latest_versions(registered_model_name)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"INFORMATIONS DU MODEL REGISTRY\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(f\"\\nNom du modèle: {registered_model.name}\")\n",
    "    print(f\"Description: {registered_model.description or 'N/A'}\")\n",
    "    print(f\"\\nVersions disponibles: {len(latest_versions)}\")\n",
    "    \n",
    "    for version in latest_versions:\n",
    "        print(f\"\\n  Version {version.version}:\")\n",
    "        print(f\"    Stage: {version.current_stage}\")\n",
    "        print(f\"    Run ID: {version.run_id}\")\n",
    "        print(f\"    Status: {version.status}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Note: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sauvegarde des informations MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informations MLflow sauvegardées: mlflow_info.pkl\n"
     ]
    }
   ],
   "source": [
    "# Créer un rapport récapitulatif\n",
    "mlflow_info = {\n",
    "    'experiment_name': experiment_name,\n",
    "    'experiment_id': experiment_id,\n",
    "    'total_runs': len(runs),\n",
    "    'best_run_id': best_run_id,\n",
    "    'best_model_key': best_model_key,\n",
    "    'best_f1_score': best_metrics['f1_weighted'],\n",
    "    'best_accuracy': best_metrics['accuracy'],\n",
    "    'registered_model_name': registered_model_name,\n",
    "    'all_run_ids': run_ids,\n",
    "    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'tracking_uri': mlflow.get_tracking_uri()\n",
    "}\n",
    "\n",
    "with open('../data/pkl/mlflow_info.pkl', 'wb') as f:\n",
    "    pickle.dump(mlflow_info, f)\n",
    "\n",
    "print(\"Informations MLflow sauvegardées: ../data/pkl/mlflow_info.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Résumé MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "RÉSUMÉ MLFLOW\n",
      "================================================================================\n",
      "\n",
      "1. EXPÉRIENCE MLFLOW:\n",
      "   - Nom: Job_Classification_Pipeline\n",
      "   - ID: 1\n",
      "   - Tracking URI: sqlite:///mlflow.db\n",
      "\n",
      "2. RUNS ENREGISTRÉS:\n",
      "   - Total: 22\n",
      "   - Modèles standards: 20\n",
      "   - Meilleur modèle: 1\n",
      "   - Métadonnées: 1\n",
      "\n",
      "3. MEILLEUR MODÈLE:\n",
      "   - Modèle: Random_Forest_Combined\n",
      "   - Run ID: 19644568d43f426693a36147e1693345\n",
      "   - Registry Name: Job_Classification_Best_Model\n",
      "   - F1-Score: 0.7556\n",
      "   - Accuracy: 0.7663\n",
      "\n",
      "4. MÉTRIQUES ENREGISTRÉES POUR CHAQUE MODÈLE:\n",
      "   - accuracy\n",
      "   - precision_weighted & precision_macro\n",
      "   - recall_weighted & recall_macro\n",
      "   - f1_weighted & f1_macro\n",
      "   - training_time\n",
      "   - prediction_time\n",
      "\n",
      "5. ARTIFACTS ENREGISTRÉS:\n",
      "   - Modèles sklearn pour tous les runs\n",
      "   - Tableau de comparaison (CSV)\n",
      "   - Meilleur modèle dans le Model Registry\n",
      "\n",
      "6. FICHIERS SAUVEGARDÉS LOCALEMENT:\n",
      "   - mlflow_info.pkl\n",
      "   - mlflow_comparison.csv\n",
      "\n",
      "7. ACCÈS À L'INTERFACE MLFLOW:\n",
      "   Commande: mlflow ui\n",
      "   URL: http://localhost:5000\n",
      "\n",
      "================================================================================\n",
      "PIPELINE COMPLET TERMINÉ AVEC SUCCÈS\n",
      "================================================================================\n",
      "\n",
      "Tous les modèles, métriques et le meilleur modèle ont été enregistrés dans MLflow.\n",
      "Vous pouvez maintenant visualiser les résultats avec 'mlflow ui'.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RÉSUMÉ MLFLOW\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n1. EXPÉRIENCE MLFLOW:\")\n",
    "print(f\"   - Nom: {experiment_name}\")\n",
    "print(f\"   - ID: {experiment_id}\")\n",
    "print(f\"   - Tracking URI: {mlflow.get_tracking_uri()}\")\n",
    "\n",
    "print(f\"\\n2. RUNS ENREGISTRÉS:\")\n",
    "print(f\"   - Total: {len(runs)}\")\n",
    "print(f\"   - Modèles standards: {len(trained_models)}\")\n",
    "print(f\"   - Meilleur modèle: 1\")\n",
    "print(f\"   - Métadonnées: 1\")\n",
    "\n",
    "print(f\"\\n3. MEILLEUR MODÈLE:\")\n",
    "print(f\"   - Modèle: {best_model_key}\")\n",
    "print(f\"   - Run ID: {best_run_id}\")\n",
    "print(f\"   - Registry Name: {registered_model_name}\")\n",
    "print(f\"   - F1-Score: {best_metrics['f1_weighted']:.4f}\")\n",
    "print(f\"   - Accuracy: {best_metrics['accuracy']:.4f}\")\n",
    "\n",
    "print(f\"\\n4. MÉTRIQUES ENREGISTRÉES POUR CHAQUE MODÈLE:\")\n",
    "print(f\"   - accuracy\")\n",
    "print(f\"   - precision_weighted & precision_macro\")\n",
    "print(f\"   - recall_weighted & recall_macro\")\n",
    "print(f\"   - f1_weighted & f1_macro\")\n",
    "print(f\"   - training_time\")\n",
    "print(f\"   - prediction_time\")\n",
    "\n",
    "print(f\"\\n5. ARTIFACTS ENREGISTRÉS:\")\n",
    "print(f\"   - Modèles sklearn pour tous les runs\")\n",
    "print(f\"   - Tableau de comparaison (CSV)\")\n",
    "print(f\"   - Meilleur modèle dans le Model Registry\")\n",
    "\n",
    "print(f\"\\n6. FICHIERS SAUVEGARDÉS LOCALEMENT:\")\n",
    "print(f\"   - ../data/pkl/mlflow_info.pkl\")\n",
    "print(f\"   - ../data/csv/mlflow_comparison.csv\")\n",
    "\n",
    "print(f\"\\n7. ACCÈS À L'INTERFACE MLFLOW:\")\n",
    "print(f\"   Commande: mlflow ui\")\n",
    "print(f\"   URL: http://localhost:5000\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PIPELINE COMPLET TERMINÉ AVEC SUCCÈS\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nTous les modèles, métriques et le meilleur modèle ont été enregistrés dans MLflow.\")\n",
    "print(\"Vous pouvez maintenant visualiser les résultats avec 'mlflow ui'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
