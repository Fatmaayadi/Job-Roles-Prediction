{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Feature Engineering\n",
    "\n",
    "Ce notebook gère la transformation des données textuelles en features numériques pour la classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import des bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bibliothèques importées avec succès\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"Bibliothèques importées avec succès\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données chargées avec succès\n",
      "X_train shape: (1966,)\n",
      "X_test shape: (492,)\n",
      "y_train shape: (1966,)\n",
      "y_test shape: (492,)\n"
     ]
    }
   ],
   "source": [
    "# Charger les données preprocessed\n",
    "with open('pkl/preprocessed_data.pkl', 'rb') as f:\n",
    "    preprocessed_data = pickle.load(f)\n",
    "\n",
    "X_train = preprocessed_data['X_train']\n",
    "X_test = preprocessed_data['X_test']\n",
    "y_train = preprocessed_data['y_train']\n",
    "y_test = preprocessed_data['y_test']\n",
    "label_encoder = preprocessed_data['label_encoder']\n",
    "\n",
    "print(f\"Données chargées avec succès\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering 1: TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Création des features TF-IDF...\n",
      "\n",
      "Shape des features TF-IDF:\n",
      "X_train_tfidf: (1966, 5000)\n",
      "X_test_tfidf: (492, 5000)\n"
     ]
    }
   ],
   "source": [
    "# Créer le vectoriseur TF-IDF\n",
    "print(\"Création des features TF-IDF...\")\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=5000,  # Limiter à 5000 features les plus importantes\n",
    "    min_df=2,  # Ignorer les termes qui apparaissent dans moins de 2 documents\n",
    "    max_df=0.8,  # Ignorer les termes qui apparaissent dans plus de 80% des documents\n",
    "    ngram_range=(1, 2),  # Utiliser des unigrammes et bigrammes\n",
    "    sublinear_tf=True  # Utiliser l'échelle logarithmique pour les fréquences\n",
    ")\n",
    "\n",
    "# Fit sur l'ensemble d'entraînement et transform les deux ensembles\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "print(f\"\\nShape des features TF-IDF:\")\n",
    "print(f\"X_train_tfidf: {X_train_tfidf.shape}\")\n",
    "print(f\"X_test_tfidf: {X_test_tfidf.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nombre total de features TF-IDF: 5000\n",
      "\n",
      "Top 20 features:\n",
      "['27001' '27001 foundation' '3d' '3d contribue' '3d unreal' '9001' 'abr'\n",
      " 'academic' 'academic coordinator' 'académiques' 'acca' 'access'\n",
      " 'access control' 'accessibility' 'accessibility git' 'accessibilité'\n",
      " 'accessibilité des' 'accompagne' 'accompagne la' 'accompagne les']\n"
     ]
    }
   ],
   "source": [
    "# Afficher les top features TF-IDF\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "print(f\"\\nNombre total de features TF-IDF: {len(feature_names)}\")\n",
    "print(f\"\\nTop 20 features:\")\n",
    "print(feature_names[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering 2: Count Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Création des features Count Vectorizer...\n",
      "\n",
      "Shape des features Count:\n",
      "X_train_count: (1966, 3000)\n",
      "X_test_count: (492, 3000)\n"
     ]
    }
   ],
   "source": [
    "# Créer le vectoriseur Count\n",
    "print(\"Création des features Count Vectorizer...\")\n",
    "\n",
    "count_vectorizer = CountVectorizer(\n",
    "    max_features=3000,\n",
    "    min_df=2,\n",
    "    max_df=0.8,\n",
    "    ngram_range=(1, 2)\n",
    ")\n",
    "\n",
    "# Fit sur l'ensemble d'entraînement et transform les deux ensembles\n",
    "X_train_count = count_vectorizer.fit_transform(X_train)\n",
    "X_test_count = count_vectorizer.transform(X_test)\n",
    "\n",
    "print(f\"\\nShape des features Count:\")\n",
    "print(f\"X_train_count: {X_train_count.shape}\")\n",
    "print(f\"X_test_count: {X_test_count.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering 3: TF-IDF avec réduction de dimensionnalité (SVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Création des features TF-IDF + SVD...\n",
      "Shape avant SVD:\n",
      "X_train_tfidf_full: (1966, 10000)\n"
     ]
    }
   ],
   "source": [
    "# Créer un TF-IDF avec plus de features pour la réduction\n",
    "print(\"Création des features TF-IDF + SVD...\")\n",
    "\n",
    "tfidf_vectorizer_svd = TfidfVectorizer(\n",
    "    max_features=10000,\n",
    "    min_df=2,\n",
    "    max_df=0.8,\n",
    "    ngram_range=(1, 3),\n",
    "    sublinear_tf=True\n",
    ")\n",
    "\n",
    "X_train_tfidf_full = tfidf_vectorizer_svd.fit_transform(X_train)\n",
    "X_test_tfidf_full = tfidf_vectorizer_svd.transform(X_test)\n",
    "\n",
    "print(f\"Shape avant SVD:\")\n",
    "print(f\"X_train_tfidf_full: {X_train_tfidf_full.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape après SVD:\n",
      "X_train_svd: (1966, 300)\n",
      "X_test_svd: (492, 300)\n",
      "\n",
      "Variance expliquée par les composantes: 0.5035\n"
     ]
    }
   ],
   "source": [
    "# Appliquer TruncatedSVD pour réduire la dimensionnalité\n",
    "svd = TruncatedSVD(n_components=300, random_state=42)\n",
    "\n",
    "X_train_svd = svd.fit_transform(X_train_tfidf_full)\n",
    "X_test_svd = svd.transform(X_test_tfidf_full)\n",
    "\n",
    "print(f\"\\nShape après SVD:\")\n",
    "print(f\"X_train_svd: {X_train_svd.shape}\")\n",
    "print(f\"X_test_svd: {X_test_svd.shape}\")\n",
    "print(f\"\\nVariance expliquée par les composantes: {svd.explained_variance_ratio_.sum():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering 4: Features statistiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Création des features statistiques...\n",
      "\n",
      "Shape des features statistiques:\n",
      "X_train_stats: (1966, 5)\n",
      "X_test_stats: (492, 5)\n"
     ]
    }
   ],
   "source": [
    "# Créer des features statistiques basiques\n",
    "def create_statistical_features(text_series):\n",
    "    \"\"\"\n",
    "    Crée des features statistiques à partir du texte\n",
    "    \"\"\"\n",
    "    features = pd.DataFrame()\n",
    "    \n",
    "    # Longueur du texte\n",
    "    features['text_length'] = text_series.apply(len)\n",
    "    \n",
    "    # Nombre de mots\n",
    "    features['word_count'] = text_series.apply(lambda x: len(x.split()))\n",
    "    \n",
    "    # Longueur moyenne des mots\n",
    "    features['avg_word_length'] = text_series.apply(\n",
    "        lambda x: np.mean([len(word) for word in x.split()]) if len(x.split()) > 0 else 0\n",
    "    )\n",
    "    \n",
    "    # Nombre de mots uniques\n",
    "    features['unique_words'] = text_series.apply(\n",
    "        lambda x: len(set(x.split()))\n",
    "    )\n",
    "    \n",
    "    # Ratio de mots uniques\n",
    "    features['unique_ratio'] = features['unique_words'] / (features['word_count'] + 1)\n",
    "    \n",
    "    return features.values\n",
    "\n",
    "print(\"Création des features statistiques...\")\n",
    "\n",
    "X_train_stats = create_statistical_features(X_train)\n",
    "X_test_stats = create_statistical_features(X_test)\n",
    "\n",
    "print(f\"\\nShape des features statistiques:\")\n",
    "print(f\"X_train_stats: {X_train_stats.shape}\")\n",
    "print(f\"X_test_stats: {X_test_stats.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combinaison de features: TF-IDF + Features statistiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combinaison TF-IDF + Features statistiques...\n",
      "\n",
      "Shape des features combinées:\n",
      "X_train_combined: (1966, 5005)\n",
      "X_test_combined: (492, 5005)\n"
     ]
    }
   ],
   "source": [
    "# Combiner TF-IDF avec features statistiques\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "\n",
    "print(\"Combinaison TF-IDF + Features statistiques...\")\n",
    "\n",
    "X_train_combined = hstack([X_train_tfidf, csr_matrix(X_train_stats)])\n",
    "X_test_combined = hstack([X_test_tfidf, csr_matrix(X_test_stats)])\n",
    "\n",
    "print(f\"\\nShape des features combinées:\")\n",
    "print(f\"X_train_combined: {X_train_combined.shape}\")\n",
    "print(f\"X_test_combined: {X_test_combined.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sauvegarde de toutes les représentations de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tous les ensembles de features sauvegardés: pkl/feature_sets.pkl\n"
     ]
    }
   ],
   "source": [
    "# Sauvegarder tous les ensembles de features et les vectorizers\n",
    "feature_sets = {\n",
    "    # Ensembles de features\n",
    "    'X_train_tfidf': X_train_tfidf,\n",
    "    'X_test_tfidf': X_test_tfidf,\n",
    "    'X_train_count': X_train_count,\n",
    "    'X_test_count': X_test_count,\n",
    "    'X_train_svd': X_train_svd,\n",
    "    'X_test_svd': X_test_svd,\n",
    "    'X_train_stats': X_train_stats,\n",
    "    'X_test_stats': X_test_stats,\n",
    "    'X_train_combined': X_train_combined,\n",
    "    'X_test_combined': X_test_combined,\n",
    "    \n",
    "    # Labels\n",
    "    'y_train': y_train,\n",
    "    'y_test': y_test,\n",
    "    \n",
    "    # Vectorizers et transformers\n",
    "    'tfidf_vectorizer': tfidf_vectorizer,\n",
    "    'count_vectorizer': count_vectorizer,\n",
    "    'tfidf_vectorizer_svd': tfidf_vectorizer_svd,\n",
    "    'svd': svd,\n",
    "    'label_encoder': label_encoder\n",
    "}\n",
    "\n",
    "with open('pkl/feature_sets.pkl', 'wb') as f:\n",
    "    pickle.dump(feature_sets, f)\n",
    "\n",
    "print(\"Tous les ensembles de features sauvegardés: pkl/feature_sets.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Résumé du Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RÉSUMÉ DU FEATURE ENGINEERING\n",
      "============================================================\n",
      "\n",
      "1. REPRÉSENTATIONS DE FEATURES CRÉÉES:\n",
      "   a) TF-IDF (5000 features):\n",
      "      - Train: (1966, 5000)\n",
      "      - Test: (492, 5000)\n",
      "\n",
      "   b) Count Vectorizer (3000 features):\n",
      "      - Train: (1966, 3000)\n",
      "      - Test: (492, 3000)\n",
      "\n",
      "   c) TF-IDF + SVD (300 composantes):\n",
      "      - Train: (1966, 300)\n",
      "      - Test: (492, 300)\n",
      "      - Variance expliquée: 0.5035\n",
      "\n",
      "   d) Features statistiques (5 features):\n",
      "      - Train: (1966, 5)\n",
      "      - Test: (492, 5)\n",
      "\n",
      "   e) TF-IDF + Stats combinées (5005 features):\n",
      "      - Train: (1966, 5005)\n",
      "      - Test: (492, 5005)\n",
      "\n",
      "2. FICHIERS SAUVEGARDÉS:\n",
      "   - pkl/feature_sets.pkl (tous les ensembles de features)\n",
      "\n",
      "3. PRÊT POUR LE MODELING:\n",
      "   - 5 représentations différentes de features\n",
      "   - Tous les vectorizers/transformers sauvegardés\n",
      "   - Labels d'entraînement et de test disponibles\n",
      "\n",
      "============================================================\n",
      "FEATURE ENGINEERING TERMINÉ AVEC SUCCÈS\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"RÉSUMÉ DU FEATURE ENGINEERING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n1. REPRÉSENTATIONS DE FEATURES CRÉÉES:\")\n",
    "print(\"   a) TF-IDF (5000 features):\")\n",
    "print(f\"      - Train: {X_train_tfidf.shape}\")\n",
    "print(f\"      - Test: {X_test_tfidf.shape}\")\n",
    "\n",
    "print(\"\\n   b) Count Vectorizer (3000 features):\")\n",
    "print(f\"      - Train: {X_train_count.shape}\")\n",
    "print(f\"      - Test: {X_test_count.shape}\")\n",
    "\n",
    "print(\"\\n   c) TF-IDF + SVD (300 composantes):\")\n",
    "print(f\"      - Train: {X_train_svd.shape}\")\n",
    "print(f\"      - Test: {X_test_svd.shape}\")\n",
    "print(f\"      - Variance expliquée: {svd.explained_variance_ratio_.sum():.4f}\")\n",
    "\n",
    "print(\"\\n   d) Features statistiques (5 features):\")\n",
    "print(f\"      - Train: {X_train_stats.shape}\")\n",
    "print(f\"      - Test: {X_test_stats.shape}\")\n",
    "\n",
    "print(\"\\n   e) TF-IDF + Stats combinées (5005 features):\")\n",
    "print(f\"      - Train: {X_train_combined.shape}\")\n",
    "print(f\"      - Test: {X_test_combined.shape}\")\n",
    "\n",
    "print(\"\\n2. FICHIERS SAUVEGARDÉS:\")\n",
    "print(\"   - pkl/feature_sets.pkl (tous les ensembles de features)\")\n",
    "\n",
    "print(\"\\n3. PRÊT POUR LE MODELING:\")\n",
    "print(\"   - 5 représentations différentes de features\")\n",
    "print(\"   - Tous les vectorizers/transformers sauvegardés\")\n",
    "print(\"   - Labels d'entraînement et de test disponibles\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FEATURE ENGINEERING TERMINÉ AVEC SUCCÈS\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
