{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Modeling avec GridSearchCV\n",
    "\n",
    "Ce notebook entra√Æne plusieurs mod√®les de classification, optimise leurs hyperparam√®tres avec GridSearchCV, compare leurs performances et s√©lectionne automatiquement le meilleur mod√®le"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import des biblioth√®ques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biblioth√®ques import√©es avec succ√®s\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Mod√®les de classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# GridSearchCV pour optimisation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# M√©triques\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    make_scorer\n",
    ")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Biblioth√®ques import√©es avec succ√®s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features charg√©es avec succ√®s\n",
      "Nombre de classes: 119\n"
     ]
    }
   ],
   "source": [
    "# Charger les ensembles de features\n",
    "with open('pkl/feature_sets.pkl', 'rb') as f:\n",
    "    feature_sets = pickle.load(f)\n",
    "\n",
    "# Extraire les features et labels\n",
    "X_train_tfidf = feature_sets['X_train_tfidf']\n",
    "X_test_tfidf = feature_sets['X_test_tfidf']\n",
    "X_train_count = feature_sets['X_train_count']\n",
    "X_test_count = feature_sets['X_test_count']\n",
    "X_train_svd = feature_sets['X_train_svd']\n",
    "X_test_svd = feature_sets['X_test_svd']\n",
    "X_train_combined = feature_sets['X_train_combined']\n",
    "X_test_combined = feature_sets['X_test_combined']\n",
    "\n",
    "y_train = feature_sets['y_train']\n",
    "y_test = feature_sets['y_test']\n",
    "label_encoder = feature_sets['label_encoder']\n",
    "\n",
    "print(\"Features charg√©es avec succ√®s\")\n",
    "print(f\"Nombre de classes: {len(label_encoder.classes_)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D√©finition des mod√®les (sans Gradient Boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de mod√®les d√©finis: 6\n",
      "Mod√®les: ['Logistic_Regression', 'Multinomial_NB', 'Linear_SVC', 'Random_Forest', 'KNN', 'Decision_Tree']\n"
     ]
    }
   ],
   "source": [
    "# D√©finir les mod√®les de base (sans optimisation)\n",
    "base_models = {\n",
    "    'Logistic_Regression': LogisticRegression(\n",
    "        max_iter=1000, \n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        solver='saga'\n",
    "    ),\n",
    "    'Multinomial_NB': MultinomialNB(),\n",
    "    'Linear_SVC': LinearSVC(\n",
    "        max_iter=1000, \n",
    "        random_state=42\n",
    "    ),\n",
    "    'Random_Forest': RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=20,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'KNN': KNeighborsClassifier(\n",
    "        n_neighbors=5,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'Decision_Tree': DecisionTreeClassifier(\n",
    "        max_depth=20,\n",
    "        random_state=42\n",
    "    )\n",
    "}\n",
    "\n",
    "print(f\"Nombre de mod√®les d√©finis: {len(base_models)}\")\n",
    "print(f\"Mod√®les: {list(base_models.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D√©finition des grilles d'hyperparam√®tres pour GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grilles d'hyperparam√®tres d√©finies:\n",
      "  Logistic_Regression: 16 combinaisons\n",
      "  Multinomial_NB: 5 combinaisons\n",
      "  Linear_SVC: 8 combinaisons\n",
      "  Random_Forest: 18 combinaisons\n",
      "  KNN: 8 combinaisons\n",
      "  Decision_Tree: 12 combinaisons\n"
     ]
    }
   ],
   "source": [
    "# Grilles d'hyperparam√®tres pour chaque mod√®le\n",
    "param_grids = {\n",
    "    'Logistic_Regression': {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'solver': ['saga', 'liblinear'],\n",
    "        'max_iter': [1000, 2000]\n",
    "    },\n",
    "    'Multinomial_NB': {\n",
    "        'alpha': [0.01, 0.1, 0.5, 1.0, 2.0]\n",
    "    },\n",
    "    'Linear_SVC': {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'max_iter': [1000, 2000]\n",
    "    },\n",
    "    'Random_Forest': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [10, 20, 30],\n",
    "        'min_samples_split': [2, 5]\n",
    "    },\n",
    "    'KNN': {\n",
    "        'n_neighbors': [3, 5, 7, 9],\n",
    "        'weights': ['uniform', 'distance']\n",
    "    },\n",
    "    'Decision_Tree': {\n",
    "        'max_depth': [10, 20, 30, None],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Grilles d'hyperparam√®tres d√©finies:\")\n",
    "for model_name, params in param_grids.items():\n",
    "    n_combinations = np.prod([len(v) for v in params.values()])\n",
    "    print(f\"  {model_name}: {n_combinations} combinaisons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nombre de configurations de features: 4\n",
      "Configurations: ['TF-IDF', 'Count', 'SVD', 'Combined']\n",
      "\n",
      "Mod√®les ignor√©s pour 'Combined': ['Logistic_Regression', 'Linear_SVC', 'KNN']\n"
     ]
    }
   ],
   "source": [
    "# D√©finir les configurations de features\n",
    "feature_configurations = {\n",
    "    'TF-IDF': (X_train_tfidf, X_test_tfidf),\n",
    "    'Count': (X_train_count, X_test_count),\n",
    "    'SVD': (X_train_svd, X_test_svd),\n",
    "    'Combined': (X_train_combined, X_test_combined)\n",
    "}\n",
    "\n",
    "# Mod√®les √† ignorer pour Combined (n√©cessitent normalisation)\n",
    "skip_combined = ['Logistic_Regression', 'Linear_SVC', 'KNN']\n",
    "\n",
    "print(f\"\\nNombre de configurations de features: {len(feature_configurations)}\")\n",
    "print(f\"Configurations: {list(feature_configurations.keys())}\")\n",
    "print(f\"\\nMod√®les ignor√©s pour 'Combined': {skip_combined}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonction d'√©valuation avec GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fonction d'√©valuation avec GridSearchCV d√©finie\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model_with_gridsearch(model, param_grid, X_train, X_test, y_train, y_test, model_name):\n",
    "    \"\"\"\n",
    "    Entra√Æne et √©value un mod√®le avec GridSearchCV\n",
    "    Retourne les m√©triques, le meilleur mod√®le et les meilleurs param√®tres\n",
    "    \"\"\"\n",
    "    print(f\"    üîç GridSearchCV en cours...\")\n",
    "    \n",
    "    # D√©finir le scorer\n",
    "    scorer = make_scorer(f1_score, average='weighted', zero_division=0)\n",
    "    \n",
    "    # GridSearchCV\n",
    "    start_time = time.time()\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grid,\n",
    "        cv=3,  # 3-fold cross-validation\n",
    "        scoring=scorer,\n",
    "        n_jobs=-1,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Meilleur mod√®le\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "    best_cv_score = grid_search.best_score_\n",
    "    \n",
    "    # Pr√©dictions sur le test\n",
    "    start_time = time.time()\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    prediction_time = time.time() - start_time\n",
    "    \n",
    "    # Calcul des m√©triques\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision_weighted': precision_score(y_test, y_pred, average='weighted', zero_division=0),\n",
    "        'recall_weighted': recall_score(y_test, y_pred, average='weighted', zero_division=0),\n",
    "        'f1_weighted': f1_score(y_test, y_pred, average='weighted', zero_division=0),\n",
    "        'precision_macro': precision_score(y_test, y_pred, average='macro', zero_division=0),\n",
    "        'recall_macro': recall_score(y_test, y_pred, average='macro', zero_division=0),\n",
    "        'f1_macro': f1_score(y_test, y_pred, average='macro', zero_division=0),\n",
    "        'training_time': training_time,\n",
    "        'prediction_time': prediction_time,\n",
    "        'best_cv_score': best_cv_score\n",
    "    }\n",
    "    \n",
    "    return metrics, best_model, y_pred, best_params\n",
    "\n",
    "print(\"Fonction d'√©valuation avec GridSearchCV d√©finie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entra√Ænement et √©valuation de tous les mod√®les avec GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "D√âBUT DE L'ENTRA√éNEMENT DES MOD√àLES AVEC GRIDSEARCHCV\n",
      "================================================================================\n",
      "\n",
      "‚ö†Ô∏è  NOTE: GridSearchCV prend plus de temps mais optimise les hyperparam√®tres\n",
      "    Chaque mod√®le teste plusieurs combinaisons de param√®tres avec CV 3-fold\n",
      "\n",
      "\n",
      "================================================================================\n",
      "CONFIGURATION DE FEATURES: TF-IDF\n",
      "================================================================================\n",
      "\n",
      "[1/21] Entra√Ænement: Logistic_Regression avec TF-IDF\n",
      "    üîç GridSearchCV en cours...\n",
      "    ‚úì Meilleurs param√®tres: {'C': 100, 'max_iter': 1000, 'solver': 'saga'}\n",
      "    ‚úì CV Score: 0.7185\n",
      "    ‚úì Test Accuracy: 0.7337\n",
      "    ‚úì Test F1-Score (weighted): 0.7329\n",
      "    ‚úì Test F1-Score (macro): 0.7243\n",
      "    ‚úì Temps d'entra√Ænement: 133.68s\n",
      "\n",
      "[2/21] Entra√Ænement: Multinomial_NB avec TF-IDF\n",
      "    üîç GridSearchCV en cours...\n",
      "    ‚úì Meilleurs param√®tres: {'alpha': 0.1}\n",
      "    ‚úì CV Score: 0.6176\n",
      "    ‚úì Test Accuracy: 0.6463\n",
      "    ‚úì Test F1-Score (weighted): 0.6363\n",
      "    ‚úì Test F1-Score (macro): 0.6436\n",
      "    ‚úì Temps d'entra√Ænement: 0.68s\n",
      "\n",
      "[3/21] Entra√Ænement: Linear_SVC avec TF-IDF\n",
      "    üîç GridSearchCV en cours...\n",
      "    ‚úì Meilleurs param√®tres: {'C': 10, 'max_iter': 1000}\n",
      "    ‚úì CV Score: 0.7261\n",
      "    ‚úì Test Accuracy: 0.7215\n",
      "    ‚úì Test F1-Score (weighted): 0.7163\n",
      "    ‚úì Test F1-Score (macro): 0.7095\n",
      "    ‚úì Temps d'entra√Ænement: 5.81s\n",
      "\n",
      "[4/21] Entra√Ænement: Random_Forest avec TF-IDF\n",
      "    üîç GridSearchCV en cours...\n",
      "    ‚úì Meilleurs param√®tres: {'max_depth': 30, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "    ‚úì CV Score: 0.6972\n",
      "    ‚úì Test Accuracy: 0.7520\n",
      "    ‚úì Test F1-Score (weighted): 0.7397\n",
      "    ‚úì Test F1-Score (macro): 0.7175\n",
      "    ‚úì Temps d'entra√Ænement: 44.38s\n",
      "\n",
      "[5/21] Entra√Ænement: KNN avec TF-IDF\n",
      "    üîç GridSearchCV en cours...\n",
      "    ‚úì Meilleurs param√®tres: {'n_neighbors': 9, 'weights': 'distance'}\n",
      "    ‚úì CV Score: 0.6088\n",
      "    ‚úì Test Accuracy: 0.6382\n",
      "    ‚úì Test F1-Score (weighted): 0.6238\n",
      "    ‚úì Test F1-Score (macro): 0.6373\n",
      "    ‚úì Temps d'entra√Ænement: 1.74s\n",
      "\n",
      "[6/21] Entra√Ænement: Decision_Tree avec TF-IDF\n",
      "    üîç GridSearchCV en cours...\n",
      "    ‚úì Meilleurs param√®tres: {'max_depth': None, 'min_samples_split': 5}\n",
      "    ‚úì CV Score: 0.6191\n",
      "    ‚úì Test Accuracy: 0.6850\n",
      "    ‚úì Test F1-Score (weighted): 0.6820\n",
      "    ‚úì Test F1-Score (macro): 0.6932\n",
      "    ‚úì Temps d'entra√Ænement: 13.95s\n",
      "\n",
      "================================================================================\n",
      "CONFIGURATION DE FEATURES: Count\n",
      "================================================================================\n",
      "\n",
      "[7/21] Entra√Ænement: Logistic_Regression avec Count\n",
      "    üîç GridSearchCV en cours...\n",
      "    ‚úì Meilleurs param√®tres: {'C': 10, 'max_iter': 1000, 'solver': 'liblinear'}\n",
      "    ‚úì CV Score: 0.7278\n",
      "    ‚úì Test Accuracy: 0.7419\n",
      "    ‚úì Test F1-Score (weighted): 0.7405\n",
      "    ‚úì Test F1-Score (macro): 0.7293\n",
      "    ‚úì Temps d'entra√Ænement: 299.32s\n",
      "\n",
      "[8/21] Entra√Ænement: Multinomial_NB avec Count\n",
      "    üîç GridSearchCV en cours...\n",
      "    ‚úì Meilleurs param√®tres: {'alpha': 1.0}\n",
      "    ‚úì CV Score: 0.6171\n",
      "    ‚úì Test Accuracy: 0.6585\n",
      "    ‚úì Test F1-Score (weighted): 0.6433\n",
      "    ‚úì Test F1-Score (macro): 0.6296\n",
      "    ‚úì Temps d'entra√Ænement: 0.38s\n",
      "\n",
      "[9/21] Entra√Ænement: Linear_SVC avec Count\n",
      "    üîç GridSearchCV en cours...\n",
      "    ‚úì Meilleurs param√®tres: {'C': 0.1, 'max_iter': 1000}\n",
      "    ‚úì CV Score: 0.7282\n",
      "    ‚úì Test Accuracy: 0.7256\n",
      "    ‚úì Test F1-Score (weighted): 0.7221\n",
      "    ‚úì Test F1-Score (macro): 0.6990\n",
      "    ‚úì Temps d'entra√Ænement: 5.62s\n",
      "\n",
      "[10/21] Entra√Ænement: Random_Forest avec Count\n",
      "    üîç GridSearchCV en cours...\n",
      "    ‚úì Meilleurs param√®tres: {'max_depth': 30, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "    ‚úì CV Score: 0.7091\n",
      "    ‚úì Test Accuracy: 0.7622\n",
      "    ‚úì Test F1-Score (weighted): 0.7510\n",
      "    ‚úì Test F1-Score (macro): 0.7525\n",
      "    ‚úì Temps d'entra√Ænement: 31.63s\n",
      "\n",
      "[11/21] Entra√Ænement: KNN avec Count\n",
      "    üîç GridSearchCV en cours...\n",
      "    ‚úì Meilleurs param√®tres: {'n_neighbors': 9, 'weights': 'distance'}\n",
      "    ‚úì CV Score: 0.5196\n",
      "    ‚úì Test Accuracy: 0.5447\n",
      "    ‚úì Test F1-Score (weighted): 0.5377\n",
      "    ‚úì Test F1-Score (macro): 0.5766\n",
      "    ‚úì Temps d'entra√Ænement: 2.57s\n",
      "\n",
      "[12/21] Entra√Ænement: Decision_Tree avec Count\n",
      "    üîç GridSearchCV en cours...\n",
      "    ‚úì Meilleurs param√®tres: {'max_depth': None, 'min_samples_split': 2}\n",
      "    ‚úì CV Score: 0.6320\n",
      "    ‚úì Test Accuracy: 0.6768\n",
      "    ‚úì Test F1-Score (weighted): 0.6720\n",
      "    ‚úì Test F1-Score (macro): 0.6533\n",
      "    ‚úì Temps d'entra√Ænement: 4.44s\n",
      "\n",
      "================================================================================\n",
      "CONFIGURATION DE FEATURES: SVD\n",
      "================================================================================\n",
      "\n",
      "[13/21] Entra√Ænement: Logistic_Regression avec SVD\n",
      "    üîç GridSearchCV en cours...\n",
      "    ‚úì Meilleurs param√®tres: {'C': 10, 'max_iter': 1000, 'solver': 'saga'}\n",
      "    ‚úì CV Score: 0.7087\n",
      "    ‚úì Test Accuracy: 0.7337\n",
      "    ‚úì Test F1-Score (weighted): 0.7333\n",
      "    ‚úì Test F1-Score (macro): 0.7332\n",
      "    ‚úì Temps d'entra√Ænement: 404.32s\n",
      "\n",
      "‚è≠Ô∏è  [Multinomial_NB] Ignor√© pour SVD (valeurs n√©gatives)\n",
      "\n",
      "[14/21] Entra√Ænement: Linear_SVC avec SVD\n",
      "    üîç GridSearchCV en cours...\n",
      "    ‚úì Meilleurs param√®tres: {'C': 1, 'max_iter': 1000}\n",
      "    ‚úì CV Score: 0.6997\n",
      "    ‚úì Test Accuracy: 0.7276\n",
      "    ‚úì Test F1-Score (weighted): 0.7204\n",
      "    ‚úì Test F1-Score (macro): 0.7130\n",
      "    ‚úì Temps d'entra√Ænement: 88.38s\n",
      "\n",
      "[15/21] Entra√Ænement: Random_Forest avec SVD\n",
      "    üîç GridSearchCV en cours...\n",
      "    ‚úì Meilleurs param√®tres: {'max_depth': 30, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "    ‚úì CV Score: 0.6546\n",
      "    ‚úì Test Accuracy: 0.6870\n",
      "    ‚úì Test F1-Score (weighted): 0.6863\n",
      "    ‚úì Test F1-Score (macro): 0.7042\n",
      "    ‚úì Temps d'entra√Ænement: 403.67s\n",
      "\n",
      "[16/21] Entra√Ænement: KNN avec SVD\n",
      "    üîç GridSearchCV en cours...\n",
      "    ‚úì Meilleurs param√®tres: {'n_neighbors': 9, 'weights': 'distance'}\n",
      "    ‚úì CV Score: 0.6100\n",
      "    ‚úì Test Accuracy: 0.6341\n",
      "    ‚úì Test F1-Score (weighted): 0.6316\n",
      "    ‚úì Test F1-Score (macro): 0.6277\n",
      "    ‚úì Temps d'entra√Ænement: 3.17s\n",
      "\n",
      "[17/21] Entra√Ænement: Decision_Tree avec SVD\n",
      "    üîç GridSearchCV en cours...\n",
      "    ‚úì Meilleurs param√®tres: {'max_depth': None, 'min_samples_split': 5}\n",
      "    ‚úì CV Score: 0.4083\n",
      "    ‚úì Test Accuracy: 0.4512\n",
      "    ‚úì Test F1-Score (weighted): 0.4579\n",
      "    ‚úì Test F1-Score (macro): 0.4816\n",
      "    ‚úì Temps d'entra√Ænement: 107.93s\n",
      "\n",
      "================================================================================\n",
      "CONFIGURATION DE FEATURES: Combined\n",
      "================================================================================\n",
      "\n",
      "‚è≠Ô∏è  [Logistic_Regression] Ignor√© pour Combined (n√©cessite normalisation)\n",
      "\n",
      "[18/21] Entra√Ænement: Multinomial_NB avec Combined\n",
      "    üîç GridSearchCV en cours...\n",
      "    ‚úì Meilleurs param√®tres: {'alpha': 0.01}\n",
      "    ‚úì CV Score: 0.5951\n",
      "    ‚úì Test Accuracy: 0.6382\n",
      "    ‚úì Test F1-Score (weighted): 0.6329\n",
      "    ‚úì Test F1-Score (macro): 0.6606\n",
      "    ‚úì Temps d'entra√Ænement: 0.49s\n",
      "\n",
      "‚è≠Ô∏è  [Linear_SVC] Ignor√© pour Combined (n√©cessite normalisation)\n",
      "\n",
      "[19/21] Entra√Ænement: Random_Forest avec Combined\n",
      "    üîç GridSearchCV en cours...\n",
      "    ‚úì Meilleurs param√®tres: {'max_depth': 30, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "    ‚úì CV Score: 0.7085\n",
      "    ‚úì Test Accuracy: 0.7663\n",
      "    ‚úì Test F1-Score (weighted): 0.7556\n",
      "    ‚úì Test F1-Score (macro): 0.7349\n",
      "    ‚úì Temps d'entra√Ænement: 38.15s\n",
      "\n",
      "‚è≠Ô∏è  [KNN] Ignor√© pour Combined (n√©cessite normalisation)\n",
      "\n",
      "[20/21] Entra√Ænement: Decision_Tree avec Combined\n",
      "    üîç GridSearchCV en cours...\n",
      "    ‚úì Meilleurs param√®tres: {'max_depth': None, 'min_samples_split': 5}\n",
      "    ‚úì CV Score: 0.6085\n",
      "    ‚úì Test Accuracy: 0.6850\n",
      "    ‚úì Test F1-Score (weighted): 0.6822\n",
      "    ‚úì Test F1-Score (macro): 0.6805\n",
      "    ‚úì Temps d'entra√Ænement: 13.04s\n",
      "\n",
      "================================================================================\n",
      "ENTRA√éNEMENT TERMIN√â\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Dictionnaire pour stocker tous les r√©sultats\n",
    "all_results = []\n",
    "trained_models = {}\n",
    "best_params_dict = {}\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"D√âBUT DE L'ENTRA√éNEMENT DES MOD√àLES AVEC GRIDSEARCHCV\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n‚ö†Ô∏è  NOTE: GridSearchCV prend plus de temps mais optimise les hyperparam√®tres\")\n",
    "print(\"    Chaque mod√®le teste plusieurs combinaisons de param√®tres avec CV 3-fold\\n\")\n",
    "\n",
    "total_combinations = sum(\n",
    "    1 for feature_name in feature_configurations \n",
    "    for model_name in base_models \n",
    "    if not (feature_name == 'Combined' and model_name in skip_combined)\n",
    ")\n",
    "current_combination = 0\n",
    "\n",
    "# Boucle sur toutes les combinaisons mod√®le-features\n",
    "for feature_name, (X_train_feat, X_test_feat) in feature_configurations.items():\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"CONFIGURATION DE FEATURES: {feature_name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    for model_name, model in base_models.items():\n",
    "        \n",
    "        # Ignorer Combined pour certains mod√®les\n",
    "        if feature_name == 'Combined' and model_name in skip_combined:\n",
    "            print(f\"\\n‚è≠Ô∏è  [{model_name}] Ignor√© pour {feature_name} (n√©cessite normalisation)\")\n",
    "            continue\n",
    "        \n",
    "        # Ignorer SVD pour Multinomial_NB (valeurs n√©gatives)\n",
    "        if feature_name == 'SVD' and model_name == 'Multinomial_NB':\n",
    "            print(f\"\\n‚è≠Ô∏è  [{model_name}] Ignor√© pour {feature_name} (valeurs n√©gatives)\")\n",
    "            continue\n",
    "        \n",
    "        current_combination += 1\n",
    "        print(f\"\\n[{current_combination}/{total_combinations}] Entra√Ænement: {model_name} avec {feature_name}\")\n",
    "        \n",
    "        try:\n",
    "            # √âvaluer le mod√®le avec GridSearchCV\n",
    "            metrics, trained_model, y_pred, best_params = evaluate_model_with_gridsearch(\n",
    "                model, param_grids[model_name], X_train_feat, X_test_feat, y_train, y_test, model_name\n",
    "            )\n",
    "            \n",
    "            # Stocker les r√©sultats\n",
    "            result = {\n",
    "                'model_name': model_name,\n",
    "                'feature_config': feature_name,\n",
    "                'combination': f\"{model_name}_{feature_name}\",\n",
    "                **metrics\n",
    "            }\n",
    "            all_results.append(result)\n",
    "            \n",
    "            # Stocker le mod√®le entra√Æn√©\n",
    "            model_key = f\"{model_name}_{feature_name}\"\n",
    "            trained_models[model_key] = {\n",
    "                'model': trained_model,\n",
    "                'metrics': metrics,\n",
    "                'predictions': y_pred\n",
    "            }\n",
    "            \n",
    "            # Stocker les meilleurs param√®tres\n",
    "            best_params_dict[model_key] = best_params\n",
    "            \n",
    "            # Afficher les r√©sultats\n",
    "            print(f\"    ‚úì Meilleurs param√®tres: {best_params}\")\n",
    "            print(f\"    ‚úì CV Score: {metrics['best_cv_score']:.4f}\")\n",
    "            print(f\"    ‚úì Test Accuracy: {metrics['accuracy']:.4f}\")\n",
    "            print(f\"    ‚úì Test F1-Score (weighted): {metrics['f1_weighted']:.4f}\")\n",
    "            print(f\"    ‚úì Test F1-Score (macro): {metrics['f1_macro']:.4f}\")\n",
    "            print(f\"    ‚úì Temps d'entra√Ænement: {metrics['training_time']:.2f}s\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"    ‚ùå ERREUR: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"ENTRA√éNEMENT TERMIN√â\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaison des performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "COMPARAISON DES PERFORMANCES (Top 10)\n",
      "================================================================================\n",
      "               combination  accuracy  f1_weighted  f1_macro  best_cv_score\n",
      "    Random_Forest_Combined  0.766260     0.755572  0.734941       0.708508\n",
      "       Random_Forest_Count  0.762195     0.751029  0.752502       0.709097\n",
      " Logistic_Regression_Count  0.741870     0.740510  0.729349       0.727755\n",
      "      Random_Forest_TF-IDF  0.752033     0.739744  0.717458       0.697167\n",
      "   Logistic_Regression_SVD  0.733740     0.733250  0.733212       0.708731\n",
      "Logistic_Regression_TF-IDF  0.733740     0.732886  0.724259       0.718489\n",
      "          Linear_SVC_Count  0.725610     0.722106  0.699014       0.728166\n",
      "            Linear_SVC_SVD  0.727642     0.720357  0.713030       0.699651\n",
      "         Linear_SVC_TF-IDF  0.721545     0.716254  0.709509       0.726087\n",
      "         Random_Forest_SVD  0.686992     0.686258  0.704231       0.654616\n"
     ]
    }
   ],
   "source": [
    "# Cr√©er un DataFrame avec tous les r√©sultats\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Trier par F1-score weighted (m√©trique principale)\n",
    "results_df = results_df.sort_values('f1_weighted', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARAISON DES PERFORMANCES (Top 10)\")\n",
    "print(\"=\"*80)\n",
    "print(results_df[[\n",
    "    'combination', 'accuracy', 'f1_weighted', 'f1_macro', 'best_cv_score'\n",
    "]].head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S√©lection automatique du meilleur mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MEILLEUR MOD√àLE S√âLECTIONN√â AUTOMATIQUEMENT (OPTIMIS√â AVEC GRIDSEARCHCV)\n",
      "================================================================================\n",
      "\n",
      "Combination: Random_Forest_Combined\n",
      "Mod√®le: Random_Forest\n",
      "Features: Combined\n",
      "\n",
      "MEILLEURS HYPERPARAM√àTRES:\n",
      "  max_depth: 30\n",
      "  min_samples_split: 2\n",
      "  n_estimators: 200\n",
      "\n",
      "M√âTRIQUES DE PERFORMANCE:\n",
      "  CV Score (3-fold): 0.7085\n",
      "  Test Accuracy: 0.7663\n",
      "  Test Precision (weighted): 0.7876\n",
      "  Test Recall (weighted): 0.7663\n",
      "  Test F1-Score (weighted): 0.7556\n",
      "  Test F1-Score (macro): 0.7349\n",
      "\n",
      "TEMPS:\n",
      "  Entra√Ænement (avec GridSearch): 38.15s\n",
      "  Pr√©diction: 0.4139s\n"
     ]
    }
   ],
   "source": [
    "# S√©lectionner le meilleur mod√®le bas√© sur le F1-score weighted\n",
    "best_result = results_df.iloc[0]\n",
    "best_model_key = best_result['combination']\n",
    "best_model_info = trained_models[best_model_key]\n",
    "best_params = best_params_dict[best_model_key]\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"MEILLEUR MOD√àLE S√âLECTIONN√â AUTOMATIQUEMENT (OPTIMIS√â AVEC GRIDSEARCHCV)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nCombination: {best_result['combination']}\")\n",
    "print(f\"Mod√®le: {best_result['model_name']}\")\n",
    "print(f\"Features: {best_result['feature_config']}\")\n",
    "print(f\"\\nMEILLEURS HYPERPARAM√àTRES:\")\n",
    "for param, value in best_params.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "print(f\"\\nM√âTRIQUES DE PERFORMANCE:\")\n",
    "print(f\"  CV Score (3-fold): {best_result['best_cv_score']:.4f}\")\n",
    "print(f\"  Test Accuracy: {best_result['accuracy']:.4f}\")\n",
    "print(f\"  Test Precision (weighted): {best_result['precision_weighted']:.4f}\")\n",
    "print(f\"  Test Recall (weighted): {best_result['recall_weighted']:.4f}\")\n",
    "print(f\"  Test F1-Score (weighted): {best_result['f1_weighted']:.4f}\")\n",
    "print(f\"  Test F1-Score (macro): {best_result['f1_macro']:.4f}\")\n",
    "print(f\"\\nTEMPS:\")\n",
    "print(f\"  Entra√Ænement (avec GridSearch): {best_result['training_time']:.2f}s\")\n",
    "print(f\"  Pr√©diction: {best_result['prediction_time']:.4f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rapport d√©taill√© pour le meilleur mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "RAPPORT DE CLASSIFICATION D√âTAILL√â (Meilleur Mod√®le Optimis√©)\n",
      "================================================================================\n",
      "                                              precision    recall  f1-score   support\n",
      "\n",
      "                               AI Researcher       0.80      0.80      0.80         5\n",
      "                        Academic Coordinator       1.00      1.00      1.00         3\n",
      "                           Account Executive       1.00      1.00      1.00         2\n",
      "                             Account Manager       1.00      1.00      1.00         2\n",
      "                                  Accountant       0.46      0.75      0.57         8\n",
      "                    Administrative Assistant       1.00      1.00      1.00         3\n",
      "                                Art Director       0.00      0.00      0.00         3\n",
      "                                    Attorney       1.00      1.00      1.00         4\n",
      "                                  BI Analyst       0.83      1.00      0.91         5\n",
      "                           Backend Developer       0.33      0.25      0.29        12\n",
      "                           Big Data Engineer       0.88      0.88      0.88         8\n",
      "                        Blockchain Developer       1.00      0.91      0.95        11\n",
      "                Business Development Manager       0.50      1.00      0.67         1\n",
      "         Business Development Representative       0.67      1.00      0.80         4\n",
      "                                         CEO       1.00      1.00      1.00         1\n",
      "               CFO (Chief Financial Officer)       1.00      1.00      1.00         1\n",
      "               COO (Chief Operating Officer)       1.00      0.25      0.40         4\n",
      "                                Career Coach       0.91      1.00      0.95        10\n",
      "                                Case Manager       1.00      0.50      0.67         2\n",
      "                              Chief of Staff       1.00      1.00      1.00         2\n",
      "                   Client Support Specialist       1.00      1.00      1.00         1\n",
      "                              Cloud Engineer       1.00      0.75      0.86         4\n",
      "                Construction Project Manager       0.25      0.33      0.29         3\n",
      "                Content Marketing Specialist       0.60      0.50      0.55         6\n",
      "             Customer Service Representative       1.00      0.67      0.80         3\n",
      "                    Customer Success Manager       1.00      1.00      1.00         3\n",
      "                       Cybersecurity Analyst       0.55      0.86      0.67         7\n",
      "                                Data Analyst       1.00      0.67      0.80         3\n",
      "                               Data Engineer       0.59      0.83      0.69        12\n",
      "                            Data Entry Clerk       1.00      1.00      1.00         4\n",
      "                              Data Scientist       0.00      0.00      0.00         6\n",
      "                      Database Administrator       1.00      0.73      0.84        11\n",
      "                      Deep Learning Engineer       1.00      0.78      0.88         9\n",
      "                             DevOps Engineer       0.60      0.60      0.60         5\n",
      "                Digital Marketing Specialist       1.00      0.29      0.44         7\n",
      "                                    Director       0.50      0.33      0.40         3\n",
      "                  E-commerce Project Manager       0.50      0.25      0.33         4\n",
      "                                    Educator       1.00      1.00      1.00         1\n",
      "                  Email Marketing Specialist       1.00      0.40      0.57         5\n",
      "                  Embedded Software Engineer       0.79      1.00      0.88        11\n",
      "                         Executive Assistant       1.00      1.00      1.00         2\n",
      "                           Financial Analyst       0.00      0.00      0.00         0\n",
      "                        Financial Controller       1.00      1.00      1.00         1\n",
      "                           Firmware Engineer       1.00      0.77      0.87        13\n",
      "                          Frontend Developer       0.80      0.92      0.86        13\n",
      "                        Full Stack Developer       1.00      1.00      1.00         6\n",
      "                     Game Developer (Intern)       1.00      1.00      1.00         8\n",
      "                            Graphic Designer       0.36      0.80      0.50         5\n",
      "                                 HR Director       1.00      0.92      0.96        13\n",
      "                               HR Generalist       1.00      1.00      1.00         3\n",
      "                                  HR Manager       1.00      1.00      1.00         5\n",
      "                    Healthcare Administrator       1.00      1.00      1.00         2\n",
      "                        Help Desk Technician       0.78      1.00      0.88         7\n",
      "                                  Instructor       1.00      1.00      1.00         1\n",
      "                             Inventory Clerk       0.75      1.00      0.86         3\n",
      "                                      Lawyer       1.00      1.00      1.00         4\n",
      "                             Legal Assistant       1.00      1.00      1.00         3\n",
      "                               Legal Counsel       1.00      1.00      1.00         1\n",
      "                       Logistics Coordinator       1.00      1.00      1.00         1\n",
      "                              MLOps Engineer       1.00      1.00      1.00         5\n",
      "                   Machine Learning Engineer       0.67      1.00      0.80         4\n",
      "                          Marketing Director       0.00      0.00      0.00         0\n",
      "                           Marketing Manager       1.00      1.00      1.00         2\n",
      "                           Medical Assistant       1.00      1.00      1.00         2\n",
      "                            Mobile Developer       1.00      1.00      1.00         7\n",
      "                                NLP Engineer       1.00      0.89      0.94         9\n",
      "                       Network Administrator       1.00      1.00      1.00        11\n",
      "                                Office Clerk       1.00      1.00      1.00         4\n",
      "                              Office Manager       1.00      1.00      1.00         3\n",
      "                          Operations Manager       1.00      0.50      0.67         2\n",
      "                                   Paralegal       1.00      1.00      1.00         1\n",
      "                           Platform Engineer       1.00      1.00      1.00         3\n",
      "                            Product Designer       0.50      1.00      0.67         4\n",
      "                             Product Manager       1.00      1.00      1.00         3\n",
      "                   Product Marketing Manager       1.00      1.00      1.00         3\n",
      "                             Program Manager       0.00      0.00      0.00         1\n",
      "                             Project Manager       1.00      0.67      0.80         3\n",
      "                      QA Automation Engineer       0.00      0.00      0.00         1\n",
      "                                 QA Engineer       1.00      0.33      0.50         3\n",
      "                                  QA Manager       1.00      1.00      1.00         1\n",
      "                           Real Estate Agent       1.00      1.00      1.00         2\n",
      "                                   Recruiter       0.67      1.00      0.80         2\n",
      "                            Registered Nurse       0.00      0.00      0.00         0\n",
      "                      Retail Sales Associate       1.00      1.00      1.00         1\n",
      "SDET (Software Development Engineer in Test)       0.50      0.50      0.50         2\n",
      "                              SEO Specialist       0.31      1.00      0.47         4\n",
      "                             Sales Associate       0.00      0.00      0.00         2\n",
      "            Sales Development Representative       1.00      0.33      0.50         3\n",
      "                             Sales Executive       0.00      0.00      0.00         1\n",
      "                               Sales Manager       0.50      0.50      0.50         2\n",
      "                                Scrum Master       1.00      0.50      0.67         2\n",
      "                           Security Engineer       0.40      0.40      0.40         5\n",
      "                           Senior Accountant       0.57      0.36      0.44        11\n",
      "                    Senior Software Engineer       0.62      0.50      0.56        10\n",
      "             Site Reliability Engineer (SRE)       0.50      1.00      0.67         3\n",
      "                        Social Media Manager       0.80      0.67      0.73         6\n",
      "                          Software Developer       0.60      0.86      0.71         7\n",
      "                           Software Engineer       0.40      0.50      0.44         4\n",
      "                      Software Test Engineer       1.00      1.00      1.00         1\n",
      "                        Supply Chain Analyst       1.00      1.00      1.00         4\n",
      "                       Systems Administrator       1.00      1.00      1.00         3\n",
      "               Talent Acquisition Specialist       1.00      0.67      0.80         3\n",
      "                   Technical Project Manager       0.50      1.00      0.67         1\n",
      "                     Technical Support Agent       0.00      0.00      0.00         2\n",
      "                         Training Specialist       1.00      1.00      1.00         3\n",
      "                                 UI Designer       0.75      1.00      0.86         3\n",
      "                                 UX Designer       0.00      0.00      0.00         3\n",
      "                              Vice President       0.50      1.00      0.67         4\n",
      "                             Visual Designer       0.50      0.25      0.33         4\n",
      "                           Warehouse Manager       1.00      1.00      1.00         1\n",
      "                                Web Designer       0.71      0.71      0.71        14\n",
      "                               Web Developer       0.75      0.50      0.60         6\n",
      "                Windows System Administrator       1.00      1.00      1.00         4\n",
      "                         WordPress Developer       1.00      1.00      1.00         7\n",
      "\n",
      "                                    accuracy                           0.77       492\n",
      "                                   macro avg       0.76      0.75      0.73       492\n",
      "                                weighted avg       0.79      0.77      0.76       492\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# G√©n√©rer le rapport de classification pour le meilleur mod√®le\n",
    "best_predictions = best_model_info['predictions']\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RAPPORT DE CLASSIFICATION D√âTAILL√â (Meilleur Mod√®le Optimis√©)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Ne garder que les classes r√©ellement pr√©sentes dans y_test ou dans les pr√©dictions\n",
    "present_labels = np.unique(np.concatenate([y_test.values, best_predictions]))\n",
    "target_names = label_encoder.inverse_transform(present_labels)\n",
    "\n",
    "print(classification_report(\n",
    "    y_test,\n",
    "    best_predictions,\n",
    "    labels=present_labels,\n",
    "    target_names=target_names,\n",
    "    zero_division=0\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tableau des meilleurs hyperparam√®tres par mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MEILLEURS HYPERPARAM√àTRES TROUV√âS PAR GRIDSEARCHCV\n",
      "================================================================================\n",
      "\n",
      "Logistic_Regression_TF-IDF:\n",
      "  F1-Score: 0.7329\n",
      "  Param√®tres:\n",
      "    - C: 100\n",
      "    - max_iter: 1000\n",
      "    - solver: saga\n",
      "\n",
      "Multinomial_NB_TF-IDF:\n",
      "  F1-Score: 0.6363\n",
      "  Param√®tres:\n",
      "    - alpha: 0.1\n",
      "\n",
      "Linear_SVC_TF-IDF:\n",
      "  F1-Score: 0.7163\n",
      "  Param√®tres:\n",
      "    - C: 10\n",
      "    - max_iter: 1000\n",
      "\n",
      "Random_Forest_TF-IDF:\n",
      "  F1-Score: 0.7397\n",
      "  Param√®tres:\n",
      "    - max_depth: 30\n",
      "    - min_samples_split: 2\n",
      "    - n_estimators: 200\n",
      "\n",
      "KNN_TF-IDF:\n",
      "  F1-Score: 0.6238\n",
      "  Param√®tres:\n",
      "    - n_neighbors: 9\n",
      "    - weights: distance\n",
      "\n",
      "Decision_Tree_TF-IDF:\n",
      "  F1-Score: 0.6820\n",
      "  Param√®tres:\n",
      "    - max_depth: None\n",
      "    - min_samples_split: 5\n",
      "\n",
      "Logistic_Regression_Count:\n",
      "  F1-Score: 0.7405\n",
      "  Param√®tres:\n",
      "    - C: 10\n",
      "    - max_iter: 1000\n",
      "    - solver: liblinear\n",
      "\n",
      "Multinomial_NB_Count:\n",
      "  F1-Score: 0.6433\n",
      "  Param√®tres:\n",
      "    - alpha: 1.0\n",
      "\n",
      "Linear_SVC_Count:\n",
      "  F1-Score: 0.7221\n",
      "  Param√®tres:\n",
      "    - C: 0.1\n",
      "    - max_iter: 1000\n",
      "\n",
      "Random_Forest_Count:\n",
      "  F1-Score: 0.7510\n",
      "  Param√®tres:\n",
      "    - max_depth: 30\n",
      "    - min_samples_split: 2\n",
      "    - n_estimators: 200\n",
      "\n",
      "KNN_Count:\n",
      "  F1-Score: 0.5377\n",
      "  Param√®tres:\n",
      "    - n_neighbors: 9\n",
      "    - weights: distance\n",
      "\n",
      "Decision_Tree_Count:\n",
      "  F1-Score: 0.6720\n",
      "  Param√®tres:\n",
      "    - max_depth: None\n",
      "    - min_samples_split: 2\n",
      "\n",
      "Logistic_Regression_SVD:\n",
      "  F1-Score: 0.7333\n",
      "  Param√®tres:\n",
      "    - C: 10\n",
      "    - max_iter: 1000\n",
      "    - solver: saga\n",
      "\n",
      "Linear_SVC_SVD:\n",
      "  F1-Score: 0.7204\n",
      "  Param√®tres:\n",
      "    - C: 1\n",
      "    - max_iter: 1000\n",
      "\n",
      "Random_Forest_SVD:\n",
      "  F1-Score: 0.6863\n",
      "  Param√®tres:\n",
      "    - max_depth: 30\n",
      "    - min_samples_split: 5\n",
      "    - n_estimators: 200\n",
      "\n",
      "KNN_SVD:\n",
      "  F1-Score: 0.6316\n",
      "  Param√®tres:\n",
      "    - n_neighbors: 9\n",
      "    - weights: distance\n",
      "\n",
      "Decision_Tree_SVD:\n",
      "  F1-Score: 0.4579\n",
      "  Param√®tres:\n",
      "    - max_depth: None\n",
      "    - min_samples_split: 5\n",
      "\n",
      "Multinomial_NB_Combined:\n",
      "  F1-Score: 0.6329\n",
      "  Param√®tres:\n",
      "    - alpha: 0.01\n",
      "\n",
      "Random_Forest_Combined:\n",
      "  F1-Score: 0.7556\n",
      "  Param√®tres:\n",
      "    - max_depth: 30\n",
      "    - min_samples_split: 2\n",
      "    - n_estimators: 200\n",
      "\n",
      "Decision_Tree_Combined:\n",
      "  F1-Score: 0.6822\n",
      "  Param√®tres:\n",
      "    - max_depth: None\n",
      "    - min_samples_split: 5\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MEILLEURS HYPERPARAM√àTRES TROUV√âS PAR GRIDSEARCHCV\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for model_key, params in best_params_dict.items():\n",
    "    model_result = results_df[results_df['combination'] == model_key].iloc[0]\n",
    "    print(f\"\\n{model_key}:\")\n",
    "    print(f\"  F1-Score: {model_result['f1_weighted']:.4f}\")\n",
    "    print(f\"  Param√®tres:\")\n",
    "    for param, value in params.items():\n",
    "        print(f\"    - {param}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse par type de mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PERFORMANCE MOYENNE PAR TYPE DE MOD√àLE (APR√àS OPTIMISATION)\n",
      "================================================================================\n",
      "                    accuracy         f1_weighted         f1_macro        \n",
      "                        mean     max        mean     max     mean     max\n",
      "model_name                                                               \n",
      "Decision_Tree         0.6245  0.6850      0.6235  0.6822   0.6272  0.6932\n",
      "KNN                   0.6057  0.6382      0.5977  0.6316   0.6139  0.6373\n",
      "Linear_SVC            0.7249  0.7276      0.7196  0.7221   0.7072  0.7130\n",
      "Logistic_Regression   0.7364  0.7419      0.7355  0.7405   0.7289  0.7332\n",
      "Multinomial_NB        0.6477  0.6585      0.6375  0.6433   0.6446  0.6606\n",
      "Random_Forest         0.7419  0.7663      0.7332  0.7556   0.7273  0.7525\n"
     ]
    }
   ],
   "source": [
    "# Performance moyenne par mod√®le\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PERFORMANCE MOYENNE PAR TYPE DE MOD√àLE (APR√àS OPTIMISATION)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "model_performance = results_df.groupby('model_name')[[\n",
    "    'accuracy', 'f1_weighted', 'f1_macro'\n",
    "]].agg(['mean', 'max']).round(4)\n",
    "\n",
    "print(model_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PERFORMANCE MOYENNE PAR CONFIGURATION DE FEATURES\n",
      "================================================================================\n",
      "               accuracy         f1_weighted         f1_macro        \n",
      "                   mean     max        mean     max     mean     max\n",
      "feature_config                                                      \n",
      "Combined         0.6965  0.7663      0.6902  0.7556   0.6920  0.7349\n",
      "Count            0.6850  0.7622      0.6778  0.7510   0.6734  0.7525\n",
      "SVD              0.6467  0.7337      0.6459  0.7333   0.6519  0.7332\n",
      "TF-IDF           0.6961  0.7520      0.6885  0.7397   0.6876  0.7243\n"
     ]
    }
   ],
   "source": [
    "# Performance moyenne par configuration de features\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PERFORMANCE MOYENNE PAR CONFIGURATION DE FEATURES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "feature_performance = results_df.groupby('feature_config')[[\n",
    "    'accuracy', 'f1_weighted', 'f1_macro'\n",
    "]].agg(['mean', 'max']).round(4)\n",
    "\n",
    "print(feature_performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaison: Am√©lioration apport√©e par GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "AM√âLIORATION CV vs TEST\n",
      "================================================================================\n",
      "\n",
      "Top 10 mod√®les - Comparaison CV vs Test:\n",
      "               combination  best_cv_score  f1_weighted  difference\n",
      "    Random_Forest_Combined       0.708508     0.755572    0.047064\n",
      "       Random_Forest_Count       0.709097     0.751029    0.041931\n",
      " Logistic_Regression_Count       0.727755     0.740510    0.012755\n",
      "      Random_Forest_TF-IDF       0.697167     0.739744    0.042577\n",
      "   Logistic_Regression_SVD       0.708731     0.733250    0.024519\n",
      "Logistic_Regression_TF-IDF       0.718489     0.732886    0.014397\n",
      "          Linear_SVC_Count       0.728166     0.722106   -0.006060\n",
      "            Linear_SVC_SVD       0.699651     0.720357    0.020706\n",
      "         Linear_SVC_TF-IDF       0.726087     0.716254   -0.009833\n",
      "         Random_Forest_SVD       0.654616     0.686258    0.031642\n",
      "\n",
      "üìä Statistiques:\n",
      "  Diff√©rence moyenne (Test - CV): 0.0292\n",
      "  Diff√©rence m√©diane: 0.0254\n",
      "  √âcart-type: 0.0208\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AM√âLIORATION CV vs TEST\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Comparer CV score et test score\n",
    "comparison_df = results_df[['combination', 'best_cv_score', 'f1_weighted']].copy()\n",
    "comparison_df['difference'] = comparison_df['f1_weighted'] - comparison_df['best_cv_score']\n",
    "comparison_df = comparison_df.sort_values('f1_weighted', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 mod√®les - Comparaison CV vs Test:\")\n",
    "print(comparison_df.head(10).to_string(index=False))\n",
    "\n",
    "print(\"\\nüìä Statistiques:\")\n",
    "print(f\"  Diff√©rence moyenne (Test - CV): {comparison_df['difference'].mean():.4f}\")\n",
    "print(f\"  Diff√©rence m√©diane: {comparison_df['difference'].median():.4f}\")\n",
    "print(f\"  √âcart-type: {comparison_df['difference'].std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sauvegarde des r√©sultats et mod√®les"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R√©sultats du modeling avec GridSearch sauvegard√©s: modeling_results_gridsearch.pkl\n"
     ]
    }
   ],
   "source": [
    "# Sauvegarder tous les r√©sultats\n",
    "modeling_results = {\n",
    "    'all_results': results_df,\n",
    "    'trained_models': trained_models,\n",
    "    'best_params': best_params_dict,\n",
    "    'best_model_key': best_model_key,\n",
    "    'best_model': best_model_info['model'],\n",
    "    'best_metrics': best_model_info['metrics'],\n",
    "    'best_predictions': best_predictions,\n",
    "    'best_hyperparams': best_params,\n",
    "    'label_encoder': label_encoder,\n",
    "    'y_test': y_test,\n",
    "    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'gridsearch_used': True\n",
    "}\n",
    "\n",
    "with open('pkl/modeling_results_gridsearch.pkl', 'wb') as f:\n",
    "    pickle.dump(modeling_results, f)\n",
    "\n",
    "print(\"R√©sultats du modeling avec GridSearch sauvegard√©s: pkl/modeling_results_gridsearch.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R√©sum√© du Modeling avec GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "R√âSUM√â DU MODELING AVEC GRIDSEARCHCV\n",
      "================================================================================\n",
      "\n",
      "1. MOD√àLES ENTRA√éN√âS:\n",
      "   - Nombre de types de mod√®les: 6\n",
      "   - Nombre de configurations de features: 4\n",
      "   - Total de combinaisons test√©es: 20\n",
      "   - Mod√®les ignor√©s pour 'Combined': 3\n",
      "\n",
      "2. OPTIMISATION GRIDSEARCHCV:\n",
      "   - Cross-validation: 3-fold\n",
      "   - M√©trique d'optimisation: F1-Score weighted\n",
      "   - Hyperparam√®tres optimis√©s pour chaque mod√®le: Oui\n",
      "\n",
      "3. MEILLEUR MOD√àLE:\n",
      "   - Nom: Random_Forest\n",
      "   - Features: Combined\n",
      "   - CV F1-Score: 0.7085\n",
      "   - Test F1-Score (weighted): 0.7556\n",
      "   - Test Accuracy: 0.7663\n",
      "\n",
      "4. TOP 3 MOD√àLES:\n",
      "   19. Random_Forest_Combined - F1: 0.7556\n",
      "   10. Random_Forest_Count - F1: 0.7510\n",
      "   7. Logistic_Regression_Count - F1: 0.7405\n",
      "\n",
      "5. FICHIERS SAUVEGARD√âS:\n",
      "   - modeling_results_gridsearch.pkl (tous les mod√®les et r√©sultats)\n",
      "   - model_comparison_gridsearch.csv (tableau comparatif)\n",
      "   - best_hyperparameters.csv (meilleurs hyperparam√®tres)\n",
      "\n",
      "6. AM√âLIORATION vs MOD√àLES DE BASE:\n",
      "   - GridSearchCV a optimis√© les hyperparam√®tres\n",
      "   - Cross-validation assure la g√©n√©ralisation\n",
      "   - Performance valid√©e sur ensemble de test\n",
      "\n",
      "================================================================================\n",
      "MODELING AVEC GRIDSEARCHCV TERMIN√â AVEC SUCC√àS\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"R√âSUM√â DU MODELING AVEC GRIDSEARCHCV\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n1. MOD√àLES ENTRA√éN√âS:\")\n",
    "print(f\"   - Nombre de types de mod√®les: {len(base_models)}\")\n",
    "print(f\"   - Nombre de configurations de features: {len(feature_configurations)}\")\n",
    "print(f\"   - Total de combinaisons test√©es: {len(results_df)}\")\n",
    "print(f\"   - Mod√®les ignor√©s pour 'Combined': {len(skip_combined)}\")\n",
    "\n",
    "print(f\"\\n2. OPTIMISATION GRIDSEARCHCV:\")\n",
    "print(f\"   - Cross-validation: 3-fold\")\n",
    "print(f\"   - M√©trique d'optimisation: F1-Score weighted\")\n",
    "print(f\"   - Hyperparam√®tres optimis√©s pour chaque mod√®le: Oui\")\n",
    "\n",
    "print(f\"\\n3. MEILLEUR MOD√àLE:\")\n",
    "print(f\"   - Nom: {best_result['model_name']}\")\n",
    "print(f\"   - Features: {best_result['feature_config']}\")\n",
    "print(f\"   - CV F1-Score: {best_result['best_cv_score']:.4f}\")\n",
    "print(f\"   - Test F1-Score (weighted): {best_result['f1_weighted']:.4f}\")\n",
    "print(f\"   - Test Accuracy: {best_result['accuracy']:.4f}\")\n",
    "\n",
    "print(f\"\\n4. TOP 3 MOD√àLES:\")\n",
    "for idx, row in results_df.head(3).iterrows():\n",
    "    print(f\"   {idx + 1}. {row['combination']} - F1: {row['f1_weighted']:.4f}\")\n",
    "\n",
    "print(f\"\\n5. FICHIERS SAUVEGARD√âS:\")\n",
    "print(f\"   - pkl/modeling_results_gridsearch.pkl (tous les mod√®les et r√©sultats)\")\n",
    "\n",
    "print(f\"\\n6. AM√âLIORATION vs MOD√àLES DE BASE:\")\n",
    "print(f\"   - GridSearchCV a optimis√© les hyperparam√®tres\")\n",
    "print(f\"   - Cross-validation assure la g√©n√©ralisation\")\n",
    "print(f\"   - Performance valid√©e sur ensemble de test\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODELING AVEC GRIDSEARCHCV TERMIN√â AVEC SUCC√àS\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
